{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPdObZtrRjIifTKSQT5sGUT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takayama-rado/trado_samples/blob/main/colab_files/exp_track_affine_torch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load library"
      ],
      "metadata": {
        "id": "Am8q-mPIs7gV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "OIDqM3hEs2XU"
      },
      "outputs": [],
      "source": [
        "# Standard modules.\n",
        "import sys\n",
        "import time\n",
        "\n",
        "# CV/ML.\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Python:{sys.version}\")\n",
        "print(f\"Numpy:{np.__version__}\")\n",
        "print(f\"Torch:{torch.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RGshqJ3FgLlr",
        "outputId": "70d46286-922d-4d43-a4a0-f582303ebb6c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python:3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "Numpy:1.23.5\n",
            "Torch:2.1.0+cu118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load data"
      ],
      "metadata": {
        "id": "46iI_U9YwUde"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Crl3zNYpwWnU",
        "outputId": "ff36d114-dfca-4a57-d334-70531690d904"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-28 09:22:46--  https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static.npy\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static.npy [following]\n",
            "--2023-10-28 09:22:47--  https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300608 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘finger_far0_non_static.npy’\n",
            "\n",
            "finger_far0_non_sta 100%[===================>]   2.19M  8.92MB/s    in 0.2s    \n",
            "\n",
            "2023-10-28 09:22:47 (8.92 MB/s) - ‘finger_far0_non_static.npy’ saved [2300608/2300608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static_affine.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6N763VfwX9d",
        "outputId": "4bb7a910-cc46-4998-fdbc-8a8735a602a4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-28 09:22:48--  https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static_affine.npy\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static_affine.npy [following]\n",
            "--2023-10-28 09:22:48--  https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static_affine.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300608 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘finger_far0_non_static_affine.npy’\n",
            "\n",
            "finger_far0_non_sta 100%[===================>]   2.19M  9.52MB/s    in 0.2s    \n",
            "\n",
            "2023-10-28 09:22:50 (9.52 MB/s) - ‘finger_far0_non_static_affine.npy’ saved [2300608/2300608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "spzE6k37wZlk",
        "outputId": "016282a4-7196-444d-80af-0d615ab3589c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finger_far0_non_static_affine.npy  finger_far0_non_static.npy  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Implement affine transformation"
      ],
      "metadata": {
        "id": "E0bsjEqswbx8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Based on define-by-run"
      ],
      "metadata": {
        "id": "7fr6W4vhwf4s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_affine_matrix_2d_torch(center,\n",
        "                               trans,\n",
        "                               scale,\n",
        "                               rot,\n",
        "                               skew,\n",
        "                               dtype = torch.float32):\n",
        "    device = center.device\n",
        "    center_m = torch.tensor([[1.0, 0.0, float(-center[0])],\n",
        "                             [0.0, 1.0, float(-center[1])],\n",
        "                             [0.0, 0.0, 1.0]], dtype=dtype, device=device)\n",
        "    scale_m = torch.tensor([[float(scale[0]), 0.0, 0.0],\n",
        "                            [0.0, float(scale[1]), 0.0],\n",
        "                            [0.0, 0.0, 1.0]], dtype=dtype, device=device)\n",
        "    _cos = torch.cos(rot)\n",
        "    _sin = torch.sin(rot)\n",
        "    rot_m = torch.tensor([[float(_cos), float(-_sin), 0.0],\n",
        "                          [float(_sin), float(_cos), 0.0],\n",
        "                          [0.0, 0.0, 1.0]], dtype=dtype, device=device)\n",
        "    _tan = torch.tan(skew)\n",
        "    skew_m = torch.tensor([[1.0, float(_tan[0]), 0.0],\n",
        "                           [float(_tan[1]), 1.0, 0.0],\n",
        "                           [0.0, 0.0, 1.0]], dtype=dtype, device=device)\n",
        "    move = center + trans\n",
        "    trans_m = torch.tensor([[1.0, 0.0, float(move[0])],\n",
        "                            [0.0, 1.0, float(move[1])],\n",
        "                            [0.0, 0.0, 1.0]], dtype=dtype, device=device)\n",
        "    # Make affine matrix.\n",
        "    mat = torch.eye(3, 3, dtype=dtype, device=device)\n",
        "    mat = torch.matmul(center_m, mat)\n",
        "    mat = torch.matmul(scale_m, mat)\n",
        "    mat = torch.matmul(rot_m, mat)\n",
        "    mat = torch.matmul(skew_m, mat)\n",
        "    mat = torch.matmul(trans_m, mat)\n",
        "    return mat.to(dtype)"
      ],
      "metadata": {
        "id": "um2L_Etkwjv7"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_affine_torch(inputs, mat):\n",
        "    xy = inputs[:, :, :2]\n",
        "    ones =  torch.ones([xy.shape[0], xy.shape[1], 1], device=inputs.device)\n",
        "    xy = torch.cat([xy, ones], dim=-1)\n",
        "    xy = torch.einsum(\"...j,ij\", xy, mat)\n",
        "    inputs[:, :, :2] = xy[:, :, :-1]\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "iZQNcQLYwoHc"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_perf_str(val):\n",
        "    token_si = [\"\", \"m\", \"µ\", \"n\", \"p\"]\n",
        "    exp_si = [1, 1e3, 1e6, 1e9, 1e12]\n",
        "    perf_str = f\"{val:3g}s\"\n",
        "    si = \"\"\n",
        "    sval = val\n",
        "    for token, exp in zip(token_si, exp_si):\n",
        "        if val * exp > 1.0:\n",
        "            si = token\n",
        "            sval = val * exp\n",
        "            break\n",
        "    perf_str = f\"{sval:3g}{si}s\"\n",
        "    return perf_str"
      ],
      "metadata": {
        "id": "rqilUtKQGNx4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_perf_time(intervals, top_k=None):\n",
        "    if top_k is not None:\n",
        "        intervals = np.sort(intervals)[:top_k]\n",
        "    min = intervals.min()\n",
        "    max = intervals.max()\n",
        "    mean = intervals.mean()\n",
        "    std = intervals.std()\n",
        "\n",
        "    smin = get_perf_str(min)\n",
        "    smax = get_perf_str(max)\n",
        "    mean = get_perf_str(mean)\n",
        "    std = get_perf_str(std)\n",
        "    print(f\"Summary: Max {smax}, Min {smin}, Mean +/- Std {mean} +/- {std}\")"
      ],
      "metadata": {
        "id": "qeXgc90KGPqA"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRIALS = 100\n",
        "TOPK = 10\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Target device is {DEVICE}.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASC_SvGwJwnR",
        "outputId": "8089b508-7282-429d-b53b-cae01d81010e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target device is cpu.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data.\n",
        "trackfile = \"./finger_far0_non_static.npy\"\n",
        "reffile = \"./finger_far0_non_static_affine.npy\"\n",
        "trackdata = np.load(trackfile)\n",
        "refdata = np.load(reffile)\n",
        "print(trackdata.shape)\n",
        "\n",
        "# Remove person axis.\n",
        "trackdata = trackdata[0]\n",
        "refdata = refdata[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0M7mcIUwt6E",
        "outputId": "7bb92ba0-6342-4f21-b5f2-4517a5fd61e2"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 130, 553, 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " # Get affine matrix.\n",
        "center = torch.tensor([638.0, 389.0]).to(DEVICE)\n",
        "trans = torch.tensor([100.0, 0.0]).to(DEVICE)\n",
        "scale = torch.tensor([2.0, 0.5]).to(DEVICE)\n",
        "rot = torch.tensor(np.radians(15.0)).to(DEVICE)\n",
        "skew = torch.tensor(np.radians([15.0, 15.0])).to(DEVICE)\n",
        "dtype = torch.float32\n",
        "print(\"Parameters\")\n",
        "print(\"Center:\", center)\n",
        "print(\"Trans:\", trans)\n",
        "print(\"Scale:\", scale)\n",
        "print(\"Rot:\", rot)\n",
        "print(\"Skew:\", skew)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXe1Gj3Bwveb",
        "outputId": "2c93842f-7a3e-4e58-f19f-f75475d63e95"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters\n",
            "Center: tensor([638., 389.])\n",
            "Trans: tensor([100.,   0.])\n",
            "Scale: tensor([2.0000, 0.5000])\n",
            "Rot: tensor(0.2618, dtype=torch.float64)\n",
            "Skew: tensor([0.2618, 0.2618], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testtrack = torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE)\n",
        "\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "mat = get_affine_matrix_2d_torch(center, trans, scale, rot, skew, dtype=dtype)\n",
        "newtrack = apply_affine_torch(testtrack, mat)\n",
        "interval = time.perf_counter() - start\n",
        "print(\"Time of first call\")\n",
        "print_perf_time(np.array(interval))\n",
        "\n",
        "# Evaluate difference.\n",
        "diff = (np.round(newtrack.detach().cpu().numpy()) - np.round(refdata)).sum()\n",
        "\n",
        "testtrack = torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE)\n",
        "\n",
        "intervals = []\n",
        "for _ in range(TRIALS):\n",
        "    start = time.perf_counter()\n",
        "    mat = get_affine_matrix_2d_torch(center, trans, scale, rot, skew, dtype=dtype)\n",
        "    newtrack = apply_affine_torch(testtrack, mat)\n",
        "    end = time.perf_counter()\n",
        "    intervals.append(end - start)\n",
        "intervals = np.array(intervals)\n",
        "print(\"Time after second call\")\n",
        "print_perf_time(intervals, TOPK)\n",
        "\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d5QQDbZaw-9z",
        "outputId": "a98714fd-52ae-42ff-eaff-7d76856061f8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call\n",
            "Summary: Max 108.336ms, Min 108.336ms, Mean +/- Std 108.336ms +/-   0s\n",
            "Time after second call\n",
            "Summary: Max 2.64632ms, Min 2.18331ms, Mean +/- Std 2.48955ms +/- 131.003µs\n",
            "Sum of error:0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testtrack = torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE)\n",
        "\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "mat = get_affine_matrix_2d_torch(center, trans, scale, rot, skew, dtype=dtype)\n",
        "newtrack = apply_affine_torch(testtrack[:-1], mat)\n",
        "interval = time.perf_counter() - start\n",
        "print(\"Time of first call\")\n",
        "print_perf_time(np.array(interval))\n",
        "\n",
        "testtrack = torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE)\n",
        "\n",
        "intervals = []\n",
        "for _ in range(TRIALS):\n",
        "    start = time.perf_counter()\n",
        "    mat = get_affine_matrix_2d_torch(center, trans, scale, rot, skew, dtype=dtype)\n",
        "    newtrack = apply_affine_torch(testtrack[:-1], mat)\n",
        "    end = time.perf_counter()\n",
        "    intervals.append(end - start)\n",
        "intervals = np.array(intervals)\n",
        "print(\"Time after second call\")\n",
        "print_perf_time(intervals, TOPK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ivPCoHDVxLoT",
        "outputId": "81c65909-efae-4dcc-b803-7c57c33b8256"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call\n",
            "Summary: Max 4.1607ms, Min 4.1607ms, Mean +/- Std 4.1607ms +/-   0s\n",
            "Time after second call\n",
            "Summary: Max 2.58212ms, Min 2.16192ms, Mean +/- Std 2.46093ms +/- 163.763µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Based on define-and-run"
      ],
      "metadata": {
        "id": "v9eFIlx0xS96"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.jit.script\n",
        "def get_affine_matrix_2d_torch_jit(center: torch.Tensor,\n",
        "                                   trans: torch.Tensor,\n",
        "                                   scale: torch.Tensor,\n",
        "                                   rot: torch.Tensor,\n",
        "                                   skew: torch.Tensor,\n",
        "                                   dtype: torch.dtype = torch.float32):\n",
        "    device = center.device\n",
        "    center_m = torch.tensor([[1.0, 0.0, float(-center[0])],\n",
        "                             [0.0, 1.0, float(-center[1])],\n",
        "                             [0.0, 0.0, 1.0]], dtype=dtype, device=device)\n",
        "    scale_m = torch.tensor([[float(scale[0]), 0.0, 0.0],\n",
        "                            [0.0, float(scale[1]), 0.0],\n",
        "                            [0.0, 0.0, 1.0]], dtype=dtype, device=device)\n",
        "    _cos = torch.cos(rot)\n",
        "    _sin = torch.sin(rot)\n",
        "    rot_m = torch.tensor([[float(_cos), float(-_sin), 0.0],\n",
        "                          [float(_sin), float(_cos), 0.0],\n",
        "                          [0.0, 0.0, 1.0]], dtype=dtype, device=device)\n",
        "    _tan = torch.tan(skew)\n",
        "    skew_m = torch.tensor([[1.0, float(_tan[0]), 0.0],\n",
        "                           [float(_tan[1]), 1.0, 0.0],\n",
        "                           [0.0, 0.0, 1.0]], dtype=dtype, device=device)\n",
        "    move = center + trans\n",
        "    trans_m = torch.tensor([[1.0, 0.0, float(move[0])],\n",
        "                            [0.0, 1.0, float(move[1])],\n",
        "                            [0.0, 0.0, 1.0]], dtype=dtype, device=device)\n",
        "    # Make affine matrix.\n",
        "    mat = torch.eye(3, 3, dtype=dtype, device=device)\n",
        "    mat = torch.matmul(center_m, mat)\n",
        "    mat = torch.matmul(scale_m, mat)\n",
        "    mat = torch.matmul(rot_m, mat)\n",
        "    mat = torch.matmul(skew_m, mat)\n",
        "    mat = torch.matmul(trans_m, mat)\n",
        "    return mat.to(dtype)"
      ],
      "metadata": {
        "id": "tNozKdkkxWDE"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.jit.script\n",
        "def apply_affine_torch_jit(inputs, mat):\n",
        "    xy = inputs[:, :, :2]\n",
        "    ones = torch.ones([xy.shape[0], xy.shape[1], 1], device=inputs.device)\n",
        "    xy = torch.cat([xy, ones], dim=-1)\n",
        "    xy = torch.einsum(\"...j,ij\", xy, mat)\n",
        "    inputs[:, :, :2] = xy[:, :, :-1]\n",
        "    return inputs"
      ],
      "metadata": {
        "id": "oLbub6jnxf6M"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "testtrack = torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE)\n",
        "\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "mat = get_affine_matrix_2d_torch_jit(center, trans, scale, rot, skew, dtype=dtype)\n",
        "newtrack = apply_affine_torch_jit(testtrack, mat)\n",
        "interval = time.perf_counter() - start\n",
        "print(\"Time of first call\")\n",
        "print_perf_time(np.array(interval))\n",
        "\n",
        "# Evaluate difference.\n",
        "diff = (np.round(newtrack.detach().cpu().numpy()) - np.round(refdata)).sum()\n",
        "\n",
        "testtrack = torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE)\n",
        "\n",
        "intervals = []\n",
        "for _ in range(TRIALS):\n",
        "    start = time.perf_counter()\n",
        "    mat = get_affine_matrix_2d_torch_jit(center, trans, scale, rot, skew, dtype=dtype)\n",
        "    newtrack = apply_affine_torch_jit(testtrack, mat)\n",
        "    end = time.perf_counter()\n",
        "    intervals.append(end - start)\n",
        "intervals = np.array(intervals)\n",
        "print(\"Time after second call\")\n",
        "print_perf_time(intervals, TOPK)\n",
        "\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kXjS76HpyJ0L",
        "outputId": "77a15493-1860-4993-a7a7-27f1db1064e6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call\n",
            "Summary: Max 273.576ms, Min 273.576ms, Mean +/- Std 273.576ms +/-   0s\n",
            "Time after second call\n",
            "Summary: Max 2.36849ms, Min 1.9966ms, Mean +/- Std 2.20008ms +/- 118.974µs\n",
            "Sum of error:0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "testtrack = torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE)\n",
        "\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "mat = get_affine_matrix_2d_torch_jit(center, trans, scale, rot, skew, dtype=dtype)\n",
        "newtrack = apply_affine_torch_jit(testtrack[:-1], mat)\n",
        "interval = time.perf_counter() - start\n",
        "print(\"Time of first call\")\n",
        "print_perf_time(np.array(interval))\n",
        "\n",
        "testtrack = torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE)\n",
        "\n",
        "intervals = []\n",
        "for _ in range(TRIALS):\n",
        "    start = time.perf_counter()\n",
        "    mat = get_affine_matrix_2d_torch_jit(center, trans, scale, rot, skew, dtype=dtype)\n",
        "    newtrack = apply_affine_torch_jit(testtrack[:-1], mat)\n",
        "    end = time.perf_counter()\n",
        "    intervals.append(end - start)\n",
        "intervals = np.array(intervals)\n",
        "print(\"Time after second call\")\n",
        "print_perf_time(intervals, TOPK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p0HhgJ6kySUs",
        "outputId": "59af09ce-cb84-45ed-b23c-b2c70d68f08a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call\n",
            "Summary: Max 5.03474ms, Min 5.03474ms, Mean +/- Std 5.03474ms +/-   0s\n",
            "Time after second call\n",
            "Summary: Max 2.45161ms, Min 2.04306ms, Mean +/- Std 2.30862ms +/- 145.906µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Application to randomized transformation"
      ],
      "metadata": {
        "id": "r0GXUVA68bzF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Implementation1: Call JIT function from a python process"
      ],
      "metadata": {
        "id": "QrG9zPjw8gXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomAffineTransform2D_Torch():\n",
        "    def __init__(self,\n",
        "                 center_joints,\n",
        "                 apply_ratio,\n",
        "                 trans_range,\n",
        "                 scale_range,\n",
        "                 rot_range,\n",
        "                 skew_range,\n",
        "                 random_seed=None,\n",
        "                 device=\"cpu\",\n",
        "                 dtype=torch.float32):\n",
        "\n",
        "        self.center_joints = center_joints\n",
        "        if isinstance(self.center_joints, int):\n",
        "            self.center_joints = [self.center_joints]\n",
        "\n",
        "        self.apply_ratio = apply_ratio\n",
        "        self.trans_range = trans_range\n",
        "        self.scale_range = scale_range\n",
        "        self.rot_range = np.radians(rot_range).tolist()\n",
        "        self.skew_range = np.radians(skew_range).tolist()\n",
        "        self.dtype = dtype\n",
        "        self.device = device\n",
        "        self.rng = torch.Generator(device=device)\n",
        "        if random_seed is not None:\n",
        "            self.rng.manual_seed(random_seed)\n",
        "\n",
        "    def __call__(self, inputs):\n",
        "        if torch.rand(1, generator=self.rng, device=self.device) >= self.apply_ratio:\n",
        "            return inputs\n",
        "\n",
        "        temp = inputs[:, self.center_joints, :]\n",
        "        temp = temp.reshape([inputs.shape[0], -1, inputs.shape[-1]])\n",
        "        mask = temp.sum(dim=(1, 2)) != 0\n",
        "        # Use x and y only.\n",
        "        center = temp[mask].mean(dim=0).mean(dim=0)[:2]\n",
        "\n",
        "        # Random value in [0, 1].\n",
        "        trans = torch.rand(2, generator=self.rng, device=self.device)\n",
        "        scale = torch.rand(2, generator=self.rng, device=self.device)\n",
        "        rot = torch.rand(1, generator=self.rng, device=self.device)\n",
        "        skew = torch.rand(2, generator=self.rng, device=self.device)\n",
        "        # Scale to target range.\n",
        "        trans = (self.trans_range[1] - self.trans_range[0]) * trans + self.trans_range[0]\n",
        "        scale = (self.scale_range[1] - self.scale_range[0]) * scale + self.scale_range[0]\n",
        "        rot = (self.rot_range[1] - self.rot_range[0]) * rot + self.rot_range[0]\n",
        "        skew = (self.skew_range[1] - self.skew_range[0]) * skew + self.skew_range[0]\n",
        "\n",
        "        # Calculate matrix.\n",
        "        mat = get_affine_matrix_2d_torch_jit(center, trans, scale, rot, skew,\n",
        "            dtype=self.dtype)\n",
        "\n",
        "        # Apply transform.\n",
        "        inputs = apply_affine_torch_jit(inputs, mat)\n",
        "        return inputs"
      ],
      "metadata": {
        "id": "ENTNzFkO8bZE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_fn = RandomAffineTransform2D_Torch(\n",
        "    center_joints=[11, 12],\n",
        "    apply_ratio=1.0,\n",
        "    trans_range=[-100.0, 100.0],\n",
        "    scale_range=[0.5, 2.0],\n",
        "    rot_range=[-30.0, 30.0],\n",
        "    skew_range=[-30.0, 30.0],\n",
        "    device=DEVICE,\n",
        "    dtype=dtype)"
      ],
      "metadata": {
        "id": "OU1sn-4g9Dv8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augtracks = []\n",
        "\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "temp = aug_fn(torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE))\n",
        "interval = time.perf_counter() - start\n",
        "print(\"Time of first call\")\n",
        "print_perf_time(np.array(interval))\n",
        "\n",
        "intervals = []\n",
        "for _ in range(TRIALS):\n",
        "    start = time.perf_counter()\n",
        "    augtracks.append(aug_fn(torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE)))\n",
        "    end = time.perf_counter()\n",
        "    intervals.append(end - start)\n",
        "intervals = np.array(intervals)\n",
        "print(\"Time after second call\")\n",
        "print_perf_time(intervals, TOPK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3pzIoq2k9KD1",
        "outputId": "573a12d5-d4ce-45a5-c2b4-560e42bd61f0"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call\n",
            "Summary: Max 44.1415ms, Min 44.1415ms, Mean +/- Std 44.1415ms +/-   0s\n",
            "Time after second call\n",
            "Summary: Max 4.85873ms, Min 4.56857ms, Mean +/- Std 4.74207ms +/- 84.8653µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augtracks = []\n",
        "\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "temp = aug_fn(torch.tensor(trackdata.copy().astype(np.float32)[:-1]).to(DEVICE))\n",
        "interval = time.perf_counter() - start\n",
        "print(\"Time of first call\")\n",
        "print_perf_time(np.array(interval))\n",
        "\n",
        "intervals = []\n",
        "for _ in range(TRIALS):\n",
        "    start = time.perf_counter()\n",
        "    augtracks.append(aug_fn(torch.tensor(trackdata.copy().astype(np.float32)[:-1]).to(DEVICE)))\n",
        "    end = time.perf_counter()\n",
        "    intervals.append(end - start)\n",
        "intervals = np.array(intervals)\n",
        "print(\"Time after second call\")\n",
        "print_perf_time(intervals, TOPK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1JecWyRS9dDr",
        "outputId": "1588130d-cf4a-49f5-8462-ce812d05f3e8"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call\n",
            "Summary: Max 36.8999ms, Min 36.8999ms, Mean +/- Std 36.8999ms +/-   0s\n",
            "Time after second call\n",
            "Summary: Max 3.30155ms, Min 3.14472ms, Mean +/- Std 3.23717ms +/- 59.2772µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Implementation2: Apply JIT to whole affine process (JIT compile nn.Module)."
      ],
      "metadata": {
        "id": "PDOuPsRJ9lt1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RandomAffineTransform2D_TorchModule(nn.Module):\n",
        "    def __init__(self,\n",
        "                 center_joints,\n",
        "                 apply_ratio,\n",
        "                 trans_range,\n",
        "                 scale_range,\n",
        "                 rot_range,\n",
        "                 skew_range,\n",
        "                 random_seed=None,\n",
        "                 device=\"cpu\",\n",
        "                 dtype=torch.float32):\n",
        "        super().__init__()\n",
        "\n",
        "        self.center_joints = center_joints\n",
        "        if isinstance(self.center_joints, int):\n",
        "            self.center_joints = [self.center_joints]\n",
        "\n",
        "        self.apply_ratio = apply_ratio\n",
        "        self.trans_range = trans_range\n",
        "        self.scale_range = scale_range\n",
        "        self.rot_range = np.radians(rot_range).tolist()\n",
        "        self.skew_range = np.radians(skew_range).tolist()\n",
        "        self.dtype = dtype\n",
        "        self.device = device\n",
        "        # self.rng = torch.Generator(device=device)\n",
        "        # if random_seed is not None:\n",
        "        #     self.rng.manual_seed(random_seed)\n",
        "        self.rng = None\n",
        "\n",
        "    def forward(self, inputs):\n",
        "        if torch.rand(1, generator=self.rng, device=self.device) >= self.apply_ratio:\n",
        "            return inputs\n",
        "\n",
        "        temp = inputs[:, self.center_joints, :]\n",
        "        temp = temp.reshape([inputs.shape[0], -1, inputs.shape[-1]])\n",
        "        mask = temp.sum(dim=(1, 2)) != 0\n",
        "        # Use x and y only.\n",
        "        center = temp[mask].mean(dim=0).mean(dim=0)[:2]\n",
        "\n",
        "        # Random value in [0, 1].\n",
        "        trans = torch.rand(2, generator=self.rng, device=self.device)\n",
        "        scale = torch.rand(2, generator=self.rng, device=self.device)\n",
        "        rot = torch.rand(1, generator=self.rng, device=self.device)\n",
        "        skew = torch.rand(2, generator=self.rng, device=self.device)\n",
        "        # Scale to target range.\n",
        "        trans = (self.trans_range[1] - self.trans_range[0]) * trans + self.trans_range[0]\n",
        "        scale = (self.scale_range[1] - self.scale_range[0]) * scale + self.scale_range[0]\n",
        "        rot = (self.rot_range[1] - self.rot_range[0]) * rot + self.rot_range[0]\n",
        "        skew = (self.skew_range[1] - self.skew_range[0]) * skew + self.skew_range[0]\n",
        "\n",
        "        # Calculate matrix.\n",
        "        mat = get_affine_matrix_2d_torch_jit(center, trans, scale, rot, skew,\n",
        "            dtype=self.dtype)\n",
        "\n",
        "        # Apply transform.\n",
        "        inputs = apply_affine_torch_jit(inputs, mat)\n",
        "        return inputs"
      ],
      "metadata": {
        "id": "bZYoY1w19q5t"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aug_fn = RandomAffineTransform2D_TorchModule(\n",
        "    center_joints=[11, 12],\n",
        "    apply_ratio=1.0,\n",
        "    trans_range=[-100.0, 100.0],\n",
        "    scale_range=[0.5, 2.0],\n",
        "    rot_range=[-30.0, 30.0],\n",
        "    skew_range=[-30.0, 30.0],\n",
        "    device=DEVICE,\n",
        "    dtype=dtype)\n",
        "aug_fn = torch.jit.script(aug_fn)"
      ],
      "metadata": {
        "id": "Fc_uEl6M94Rk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "augtracks = []\n",
        "\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "temp = aug_fn(torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE))\n",
        "interval = time.perf_counter() - start\n",
        "print(\"Time of first call\")\n",
        "print_perf_time(np.array(interval))\n",
        "\n",
        "intervals = []\n",
        "for _ in range(TRIALS):\n",
        "    start = time.perf_counter()\n",
        "    augtracks.append(aug_fn(torch.tensor(trackdata.copy().astype(np.float32)).to(DEVICE)))\n",
        "    end = time.perf_counter()\n",
        "    intervals.append(end - start)\n",
        "intervals = np.array(intervals)\n",
        "print(\"Time after second call\")\n",
        "print_perf_time(intervals, TOPK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9pR-_9eT9__M",
        "outputId": "576c16af-f788-4824-bc36-ecb1e6871c3e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call\n",
            "Summary: Max 23.8013ms, Min 23.8013ms, Mean +/- Std 23.8013ms +/-   0s\n",
            "Time after second call\n",
            "Summary: Max 3.11863ms, Min 2.97164ms, Mean +/- Std 3.0571ms +/- 46.2317µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "augtracks = []\n",
        "\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "temp = aug_fn(torch.tensor(trackdata.copy().astype(np.float32)[:-1]).to(DEVICE))\n",
        "interval = time.perf_counter() - start\n",
        "print(\"Time of first call\")\n",
        "print_perf_time(np.array(interval))\n",
        "\n",
        "intervals = []\n",
        "for _ in range(TRIALS):\n",
        "    start = time.perf_counter()\n",
        "    augtracks.append(aug_fn(torch.tensor(trackdata.copy().astype(np.float32)[:-1]).to(DEVICE)))\n",
        "    end = time.perf_counter()\n",
        "    intervals.append(end - start)\n",
        "intervals = np.array(intervals)\n",
        "print(\"Time after second call\")\n",
        "print_perf_time(intervals, TOPK)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N22vjWhU-D7O",
        "outputId": "101bb4be-6b79-4c4e-bba6-3f250c05e48f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call\n",
            "Summary: Max 5.28556ms, Min 5.28556ms, Mean +/- Std 5.28556ms +/-   0s\n",
            "Time after second call\n",
            "Summary: Max 2.58359ms, Min 2.46104ms, Mean +/- Std 2.55339ms +/- 35.914µs\n"
          ]
        }
      ]
    }
  ]
}