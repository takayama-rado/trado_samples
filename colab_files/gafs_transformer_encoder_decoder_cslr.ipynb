{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPkpN8lCR07wPNpJV0/wRbf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takayama-rado/trado_samples/blob/main/colab_files/gafs_transformer_encoder_decoder_cslr.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Download dataset and modules"
      ],
      "metadata": {
        "id": "eQgl6G6nE7D0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADnfnnDUE0t1",
        "outputId": "d84e8a3e-cecb-4188-874b-a7cd84134f57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "drive.mount(\"/content/drive\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Copy to local.\n",
        "!cp ./drive/MyDrive/Datasets/gafs_dataset_very_small.zip gafs_dataset.zip"
      ],
      "metadata": {
        "id": "1qMzlk1ilsWk"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o gafs_dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cnzLCqD8FR7T",
        "outputId": "73e9f639-2f47-40d2-a0c8-5b8a847c6ff8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  gafs_dataset.zip\n",
            "   creating: gafs_dataset_very_small/\n",
            "  inflating: gafs_dataset_very_small/0.hdf5  \n",
            "  inflating: gafs_dataset_very_small/1.hdf5  \n",
            "  inflating: gafs_dataset_very_small/10.hdf5  \n",
            "  inflating: gafs_dataset_very_small/102.hdf5  \n",
            "  inflating: gafs_dataset_very_small/105.hdf5  \n",
            "  inflating: gafs_dataset_very_small/107.hdf5  \n",
            "  inflating: gafs_dataset_very_small/109.hdf5  \n",
            "  inflating: gafs_dataset_very_small/112.hdf5  \n",
            "  inflating: gafs_dataset_very_small/113.hdf5  \n",
            "  inflating: gafs_dataset_very_small/115.hdf5  \n",
            "  inflating: gafs_dataset_very_small/117.hdf5  \n",
            "  inflating: gafs_dataset_very_small/121.hdf5  \n",
            "  inflating: gafs_dataset_very_small/122.hdf5  \n",
            "  inflating: gafs_dataset_very_small/125.hdf5  \n",
            "  inflating: gafs_dataset_very_small/128.hdf5  \n",
            "  inflating: gafs_dataset_very_small/13.hdf5  \n",
            "  inflating: gafs_dataset_very_small/135.hdf5  \n",
            "  inflating: gafs_dataset_very_small/136.hdf5  \n",
            "  inflating: gafs_dataset_very_small/138.hdf5  \n",
            "  inflating: gafs_dataset_very_small/141.hdf5  \n",
            "  inflating: gafs_dataset_very_small/143.hdf5  \n",
            "  inflating: gafs_dataset_very_small/145.hdf5  \n",
            "  inflating: gafs_dataset_very_small/147.hdf5  \n",
            "  inflating: gafs_dataset_very_small/15.hdf5  \n",
            "  inflating: gafs_dataset_very_small/151.hdf5  \n",
            "  inflating: gafs_dataset_very_small/153.hdf5  \n",
            "  inflating: gafs_dataset_very_small/154.hdf5  \n",
            "  inflating: gafs_dataset_very_small/157.hdf5  \n",
            "  inflating: gafs_dataset_very_small/158.hdf5  \n",
            "  inflating: gafs_dataset_very_small/160.hdf5  \n",
            "  inflating: gafs_dataset_very_small/161.hdf5  \n",
            "  inflating: gafs_dataset_very_small/168.hdf5  \n",
            "  inflating: gafs_dataset_very_small/169.hdf5  \n",
            "  inflating: gafs_dataset_very_small/171.hdf5  \n",
            "  inflating: gafs_dataset_very_small/176.hdf5  \n",
            "  inflating: gafs_dataset_very_small/178.hdf5  \n",
            "  inflating: gafs_dataset_very_small/18.hdf5  \n",
            "  inflating: gafs_dataset_very_small/181.hdf5  \n",
            "  inflating: gafs_dataset_very_small/186.hdf5  \n",
            "  inflating: gafs_dataset_very_small/187.hdf5  \n",
            "  inflating: gafs_dataset_very_small/188.hdf5  \n",
            "  inflating: gafs_dataset_very_small/192.hdf5  \n",
            "  inflating: gafs_dataset_very_small/196.hdf5  \n",
            "  inflating: gafs_dataset_very_small/2.hdf5  \n",
            "  inflating: gafs_dataset_very_small/20.hdf5  \n",
            "  inflating: gafs_dataset_very_small/202.hdf5  \n",
            "  inflating: gafs_dataset_very_small/203.hdf5  \n",
            "  inflating: gafs_dataset_very_small/21.hdf5  \n",
            "  inflating: gafs_dataset_very_small/216.hdf5  \n",
            "  inflating: gafs_dataset_very_small/217.hdf5  \n",
            "  inflating: gafs_dataset_very_small/219.hdf5  \n",
            "  inflating: gafs_dataset_very_small/223.hdf5  \n",
            "  inflating: gafs_dataset_very_small/225.hdf5  \n",
            "  inflating: gafs_dataset_very_small/227.hdf5  \n",
            "  inflating: gafs_dataset_very_small/230.hdf5  \n",
            "  inflating: gafs_dataset_very_small/231.hdf5  \n",
            "  inflating: gafs_dataset_very_small/233.hdf5  \n",
            "  inflating: gafs_dataset_very_small/236.hdf5  \n",
            "  inflating: gafs_dataset_very_small/239.hdf5  \n",
            "  inflating: gafs_dataset_very_small/24.hdf5  \n",
            "  inflating: gafs_dataset_very_small/241.hdf5  \n",
            "  inflating: gafs_dataset_very_small/242.hdf5  \n",
            "  inflating: gafs_dataset_very_small/246.hdf5  \n",
            "  inflating: gafs_dataset_very_small/25.hdf5  \n",
            "  inflating: gafs_dataset_very_small/251.hdf5  \n",
            "  inflating: gafs_dataset_very_small/254.hdf5  \n",
            "  inflating: gafs_dataset_very_small/27.hdf5  \n",
            "  inflating: gafs_dataset_very_small/36.hdf5  \n",
            "  inflating: gafs_dataset_very_small/38.hdf5  \n",
            "  inflating: gafs_dataset_very_small/4.hdf5  \n",
            "  inflating: gafs_dataset_very_small/40.hdf5  \n",
            "  inflating: gafs_dataset_very_small/43.hdf5  \n",
            "  inflating: gafs_dataset_very_small/53.hdf5  \n",
            "  inflating: gafs_dataset_very_small/56.hdf5  \n",
            "  inflating: gafs_dataset_very_small/59.hdf5  \n",
            "  inflating: gafs_dataset_very_small/6.hdf5  \n",
            "  inflating: gafs_dataset_very_small/63.hdf5  \n",
            "  inflating: gafs_dataset_very_small/68.hdf5  \n",
            "  inflating: gafs_dataset_very_small/70.hdf5  \n",
            "  inflating: gafs_dataset_very_small/71.hdf5  \n",
            "  inflating: gafs_dataset_very_small/72.hdf5  \n",
            "  inflating: gafs_dataset_very_small/73.hdf5  \n",
            "  inflating: gafs_dataset_very_small/74.hdf5  \n",
            "  inflating: gafs_dataset_very_small/76.hdf5  \n",
            "  inflating: gafs_dataset_very_small/80.hdf5  \n",
            "  inflating: gafs_dataset_very_small/81.hdf5  \n",
            "  inflating: gafs_dataset_very_small/88.hdf5  \n",
            "  inflating: gafs_dataset_very_small/89.hdf5  \n",
            "  inflating: gafs_dataset_very_small/9.hdf5  \n",
            "  inflating: gafs_dataset_very_small/92.hdf5  \n",
            "  inflating: gafs_dataset_very_small/93.hdf5  \n",
            "  inflating: gafs_dataset_very_small/95.hdf5  \n",
            "  inflating: gafs_dataset_very_small/character_to_prediction_index.json  \n",
            "  inflating: gafs_dataset_very_small/LICENSE.txt  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls gafs_dataset_very_small"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2ZWwV56FWVD",
        "outputId": "8c3f4331-ead1-4fc6-e82a-078f50690d83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.hdf5\t  135.hdf5  160.hdf5  1.hdf5\t236.hdf5  43.hdf5  80.hdf5\n",
            "102.hdf5  136.hdf5  161.hdf5  202.hdf5\t239.hdf5  4.hdf5   81.hdf5\n",
            "105.hdf5  138.hdf5  168.hdf5  203.hdf5\t241.hdf5  53.hdf5  88.hdf5\n",
            "107.hdf5  13.hdf5   169.hdf5  20.hdf5\t242.hdf5  56.hdf5  89.hdf5\n",
            "109.hdf5  141.hdf5  171.hdf5  216.hdf5\t246.hdf5  59.hdf5  92.hdf5\n",
            "10.hdf5   143.hdf5  176.hdf5  217.hdf5\t24.hdf5   63.hdf5  93.hdf5\n",
            "112.hdf5  145.hdf5  178.hdf5  219.hdf5\t251.hdf5  68.hdf5  95.hdf5\n",
            "113.hdf5  147.hdf5  181.hdf5  21.hdf5\t254.hdf5  6.hdf5   9.hdf5\n",
            "115.hdf5  151.hdf5  186.hdf5  223.hdf5\t25.hdf5   70.hdf5  character_to_prediction_index.json\n",
            "117.hdf5  153.hdf5  187.hdf5  225.hdf5\t27.hdf5   71.hdf5  LICENSE.txt\n",
            "121.hdf5  154.hdf5  188.hdf5  227.hdf5\t2.hdf5\t  72.hdf5\n",
            "122.hdf5  157.hdf5  18.hdf5   230.hdf5\t36.hdf5   73.hdf5\n",
            "125.hdf5  158.hdf5  192.hdf5  231.hdf5\t38.hdf5   74.hdf5\n",
            "128.hdf5  15.hdf5   196.hdf5  233.hdf5\t40.hdf5   76.hdf5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat gafs_dataset_very_small/character_to_prediction_index.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JLP9RpORFaLL",
        "outputId": "0a9a1597-44ab-4fd7-9a96-c970fb3648c3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\" \":0,\"!\":1,\"#\":2,\"$\":3,\"%\":4,\"&\":5,\"'\":6,\"(\":7,\")\":8,\"*\":9,\"+\":10,\",\":11,\"-\":12,\".\":13,\"\\/\":14,\"0\":15,\"1\":16,\"2\":17,\"3\":18,\"4\":19,\"5\":20,\"6\":21,\"7\":22,\"8\":23,\"9\":24,\":\":25,\";\":26,\"=\":27,\"?\":28,\"@\":29,\"[\":30,\"_\":31,\"a\":32,\"b\":33,\"c\":34,\"d\":35,\"e\":36,\"f\":37,\"g\":38,\"h\":39,\"i\":40,\"j\":41,\"k\":42,\"l\":43,\"m\":44,\"n\":45,\"o\":46,\"p\":47,\"q\":48,\"r\":49,\"s\":50,\"t\":51,\"u\":52,\"v\":53,\"w\":54,\"x\":55,\"y\":56,\"z\":57,\"~\":58}"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cat gafs_dataset_very_small/LICENSE.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1iQlJCDtU4d8",
        "outputId": "a997fb81-b423-49c5-8b0d-9e20cef67376"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The dataset provided by Natsuki Takayama (Takayama Research and Development Office) is licensed under CC-BY 4.0.\r\n",
            "Author: Copyright 2024 Natsuki Takayama\r\n",
            "Title: GASF very small dataset\r\n",
            "Original licenser: Google LLC\r\n",
            "Modification\r\n",
            "- Extract only 3 parquet file.\r\n",
            "- Packaged into HDF5 format.\r\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import h5py\n",
        "with h5py.File(\"gafs_dataset_very_small/0.hdf5\", \"r\") as fread:\n",
        "    keys = list(fread.keys())\n",
        "    print(keys[:10])\n",
        "    group = fread[keys[0]]\n",
        "    print(group.keys())\n",
        "    feature = group[\"feature\"][:]\n",
        "    token = group[\"token\"][:]\n",
        "    print(feature.shape)\n",
        "    print(token)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37SBiPQeVSB7",
        "outputId": "72a4ea94-9d77-4249-c089-7438de6b345d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['1720198121', '1722303176', '1723157122', '1731934631', '1737624109', '1739256200', '1743069372', '1743412187', '1744795751', '1746320345']\n",
            "<KeysViewHDF5 ['feature', 'token']>\n",
            "(2, 271, 543)\n",
            "[14 38 32 45 44 36 40 32 43 43 36 56 14 43 40 45 32 12 34 32 49 50 51 36\n",
            " 45 50]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/takayama-rado/trado_samples/archive/refs/tags/v0.3.6.zip -O master.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjcUxrq2VmlE",
        "outputId": "e4091f7a-0222-4c41-c369-f9a159c2d24f"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-09-21 02:16:50--  https://github.com/takayama-rado/trado_samples/archive/refs/tags/v0.3.6.zip\n",
            "Resolving github.com (github.com)... 20.205.243.166\n",
            "Connecting to github.com (github.com)|20.205.243.166|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://codeload.github.com/takayama-rado/trado_samples/zip/refs/tags/v0.3.6 [following]\n",
            "--2024-09-21 02:16:50--  https://codeload.github.com/takayama-rado/trado_samples/zip/refs/tags/v0.3.6\n",
            "Resolving codeload.github.com (codeload.github.com)... 20.205.243.165\n",
            "Connecting to codeload.github.com (codeload.github.com)|20.205.243.165|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [application/zip]\n",
            "Saving to: ‘master.zip’\n",
            "\n",
            "master.zip              [       <=>          ]  76.58M  14.4MB/s    in 6.2s    \n",
            "\n",
            "2024-09-21 02:16:57 (12.4 MB/s) - ‘master.zip’ saved [80305369]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -o master.zip -d master"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUTwKBOMVw-j",
        "outputId": "7e79c02f-2967-484c-bce6-a0a7a4ec5a0c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  master.zip\n",
            "5b1307e0c758e696f5e99e0c804b29b32d061333\n",
            "   creating: master/trado_samples-0.3.6/\n",
            "  inflating: master/trado_samples-0.3.6/.gitignore  \n",
            "  inflating: master/trado_samples-0.3.6/LICENSE  \n",
            "  inflating: master/trado_samples-0.3.6/README.md  \n",
            "   creating: master/trado_samples-0.3.6/colab_files/\n",
            " extracting: master/trado_samples-0.3.6/colab_files/.gitkeep  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_affine_np_einsum.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_jax_static.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_mpholistic_0.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_mpothers_0.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_track_affine_jax.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_track_affine_numpy.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_track_affine_tensorflow.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_track_affine_torch.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_track_interp_jax.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_track_interp_numpy_0.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_track_interp_numpy_1.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_track_interp_tensorflow.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/exp_track_interp_torch.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gafs_create_dataset.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gafs_rnn_encoder_decoder_cslr.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_access_dataset.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_conformer_encoder.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_create_dataset.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_macaronnet_encoder.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_normalize_landmarks.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_rnn_islr_model_1.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_rnn_islr_model_2.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_rnn_islr_model_3.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_select_landmarks.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_simple_attention.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_simple_islr_model.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_transformer_encoder.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_transformer_encoder_daug_drop.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_transformer_encoder_daug_hflip.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_transformer_encoder_daug_resize.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_transformer_encoder_daug_saffine.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_transformer_encoder_daug_snoise.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_transformer_encoder_daug_tclip.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_transformer_encoder_daug_tinterp.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_transformer_encoder_daug_twarping.ipynb  \n",
            "  inflating: master/trado_samples-0.3.6/colab_files/gislr_transformer_encoder_w_ls.ipynb  \n",
            "   creating: master/trado_samples-0.3.6/src/\n",
            "   creating: master/trado_samples-0.3.6/src/modules_gislr/\n",
            " extracting: master/trado_samples-0.3.6/src/modules_gislr/__init__.py  \n",
            "  inflating: master/trado_samples-0.3.6/src/modules_gislr/activation.py  \n",
            "  inflating: master/trado_samples-0.3.6/src/modules_gislr/dataset.py  \n",
            "  inflating: master/trado_samples-0.3.6/src/modules_gislr/defines.py  \n",
            "  inflating: master/trado_samples-0.3.6/src/modules_gislr/draw_functions.py  \n",
            "  inflating: master/trado_samples-0.3.6/src/modules_gislr/layers.py  \n",
            "  inflating: master/trado_samples-0.3.6/src/modules_gislr/train_functions.py  \n",
            "  inflating: master/trado_samples-0.3.6/src/modules_gislr/transforms.py  \n",
            "  inflating: master/trado_samples-0.3.6/src/modules_gislr/utils.py  \n",
            "   creating: master/trado_samples-0.3.6/test_data/\n",
            "  inflating: master/trado_samples-0.3.6/test_data/finger_far0.mp4  \n",
            "  inflating: master/trado_samples-0.3.6/test_data/finger_far0_non_static.npy  \n",
            "  inflating: master/trado_samples-0.3.6/test_data/finger_far0_non_static_affine.npy  \n",
            "  inflating: master/trado_samples-0.3.6/test_data/finger_far0_non_static_interp.npy  \n",
            "  inflating: master/trado_samples-0.3.6/test_data/finger_middle0.mp4  \n",
            "  inflating: master/trado_samples-0.3.6/test_data/finger_near0.mp4  \n",
            "  inflating: master/trado_samples-0.3.6/test_data/hand_only.mp4  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mv master/trado_samples-0.3.6/src/modules_gislr ."
      ],
      "metadata": {
        "id": "yXsIhVAWVyej"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf master master.zip gafs_dataset_very_small.zip"
      ],
      "metadata": {
        "id": "ohykNs7zV3TL"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "koeHiooRV7qr",
        "outputId": "c691fa42-79d9-490d-f377-cc371517cff7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  gafs_dataset_very_small\tgafs_dataset.zip  modules_gislr  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load library"
      ],
      "metadata": {
        "id": "ddZ2NhLDV8yK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import json\n",
        "import math\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "from functools import partial\n",
        "from inspect import signature\n",
        "from pathlib import Path\n",
        "\n",
        "# Third party's modules\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "\n",
        "from nltk.metrics.distance import edit_distance\n",
        "\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import (\n",
        "    DataLoader)\n",
        "\n",
        "from torchvision.transforms import Compose\n",
        "\n",
        "# Local modules\n",
        "sys.path.append(\"modules_gislr\")\n",
        "from modules_gislr.dataset import (\n",
        "    HDF5Dataset,\n",
        "    merge_padded_batch)\n",
        "from modules_gislr.defines import (\n",
        "    get_fullbody_landmarks\n",
        ")\n",
        "from modules_gislr.layers import (\n",
        "    MultiheadAttention,\n",
        "    PositionalEncoding,\n",
        "    PositionwiseFeedForward,\n",
        "    Identity,\n",
        "    TransformerEncoder,\n",
        "    TransformerEncoderLayer,\n",
        "    apply_norm,\n",
        "    create_norm\n",
        ")\n",
        "from modules_gislr.transforms import (\n",
        "    InsertTokensForS2S,\n",
        "    PartsBasedNormalization,\n",
        "    ReplaceNan,\n",
        "    SelectLandmarksAndFeature,\n",
        "    ToTensor\n",
        ")\n",
        "from modules_gislr.utils import (\n",
        "    make_causal_mask,\n",
        "    make_san_mask,\n",
        "    select_reluwise_activation\n",
        ")"
      ],
      "metadata": {
        "id": "8K-wtRChV-n7"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Patch for train_functions.\n",
        "# This is only required for this script.\n",
        "def forward(model, feature, tokens, feature_pad_mask, tokens_pad_mask, tokens_causal_mask=None):\n",
        "    if isinstance(model, TransformerCSLR):\n",
        "        if tokens_causal_mask is None:\n",
        "            tokens_causal_mask = make_causal_mask(tokens_pad_mask)\n",
        "        if tokens_causal_mask.shape[-1] != tokens_pad_mask.shape[-1]:\n",
        "            tokens_causal_mask = make_causal_mask(tokens_pad_mask)\n",
        "        preds = model(src_feature=feature,\n",
        "                      tgt_feature=tokens,\n",
        "                      src_causal_mask=None,\n",
        "                      src_padding_mask=feature_pad_mask,\n",
        "                      tgt_causal_mask=tokens_causal_mask,\n",
        "                      tgt_padding_mask=tokens_pad_mask)\n",
        "    else:\n",
        "        raise NotImplementedError(f\"Unknown model type:{type(model)}.\")\n",
        "    return preds, tokens_causal_mask\n",
        "\n",
        "def inference(model, feature, start_id, end_id, max_seqlen=62):\n",
        "    if isinstance(model, TransformerCSLR):\n",
        "        pred_ids, _ = model.inference(feature,\n",
        "                                      start_id,\n",
        "                                      end_id,\n",
        "                                      max_seqlen=max_seqlen)\n",
        "    else:\n",
        "        raise NotImplementedError(f\"Unknown model type:{type(model)}.\")\n",
        "    return pred_ids\n",
        "\n",
        "from modules_gislr import train_functions\n",
        "train_functions.forward = forward\n",
        "train_functions.inference = inference\n",
        "\n",
        "from modules_gislr.train_functions import (\n",
        "    LabelSmoothingCrossEntropyLoss,\n",
        "    train_loop_csir_s2s,\n",
        "    val_loop_csir_s2s,\n",
        "    test_loop_csir_s2s)"
      ],
      "metadata": {
        "id": "jK_OHa9oIvuk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Implement Transformer Encoder-Decoder CSLR model"
      ],
      "metadata": {
        "id": "Klup1x0iWlHr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer Decoder"
      ],
      "metadata": {
        "id": "lHeUXKib_6e9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoderLayer(nn.Module):\n",
        "    def __init__(self,\n",
        "                 dim_model,\n",
        "                 num_heads,\n",
        "                 dim_ffw,\n",
        "                 dropout,\n",
        "                 activation,\n",
        "                 norm_type_sattn,\n",
        "                 norm_type_cattn,\n",
        "                 norm_type_ffw,\n",
        "                 norm_eps,\n",
        "                 norm_first,\n",
        "                 add_bias):\n",
        "        super().__init__()\n",
        "\n",
        "        self.norm_first = norm_first\n",
        "\n",
        "        #################################################\n",
        "        # MHSA.\n",
        "        #################################################\n",
        "        self.self_attn = MultiheadAttention(\n",
        "            key_dim=dim_model,\n",
        "            query_dim=dim_model,\n",
        "            att_dim=dim_model,\n",
        "            out_dim=dim_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            add_bias=add_bias)\n",
        "        self.norm_sattn = create_norm(norm_type_sattn, dim_model, norm_eps, add_bias)\n",
        "\n",
        "        #################################################\n",
        "        # MHCA.\n",
        "        #################################################\n",
        "        self.cross_attn = MultiheadAttention(\n",
        "            key_dim=dim_model,\n",
        "            query_dim=dim_model,\n",
        "            att_dim=dim_model,\n",
        "            out_dim=dim_model,\n",
        "            num_heads=num_heads,\n",
        "            dropout=dropout,\n",
        "            add_bias=add_bias)\n",
        "        self.norm_cattn = create_norm(norm_type_cattn, dim_model, norm_eps, add_bias)\n",
        "\n",
        "        #################################################\n",
        "        # PFFN.\n",
        "        #################################################\n",
        "        self.ffw = PositionwiseFeedForward(\n",
        "            dim_model=dim_model,\n",
        "            dim_ffw=dim_ffw,\n",
        "            dropout=dropout,\n",
        "            activation=activation,\n",
        "            add_bias=add_bias)\n",
        "        self.norm_ffw = create_norm(norm_type_ffw, dim_model, norm_eps, add_bias)\n",
        "\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "        # To store attention weights.\n",
        "        self.sattw = None\n",
        "        self.cattw = None\n",
        "\n",
        "    def _forward_prenorm(self,\n",
        "                         tgt_feature,\n",
        "                         enc_feature,\n",
        "                         tgt_san_mask,\n",
        "                         enc_tgt_mask):\n",
        "        \"\"\"Pre-normalization structure.\n",
        "\n",
        "        For the details, please refer\n",
        "        https://arxiv.org/pdf/2002.04745v1.pdf\n",
        "        \"\"\"\n",
        "        #################################################\n",
        "        # self-attention\n",
        "        #################################################\n",
        "        residual = tgt_feature\n",
        "        tgt_feature = apply_norm(self.norm_sattn, tgt_feature)\n",
        "        tgt_feature, self.sattw = self.self_attn(\n",
        "            key=tgt_feature,\n",
        "            value=tgt_feature,\n",
        "            query=tgt_feature,\n",
        "            mask=tgt_san_mask)\n",
        "        tgt_feature = self.dropout(tgt_feature) + residual\n",
        "\n",
        "        #################################################\n",
        "        # cross-attention\n",
        "        #################################################\n",
        "        residual = tgt_feature\n",
        "        tgt_feature = apply_norm(self.norm_cattn, tgt_feature)\n",
        "        tgt_feature, self.cattw = self.cross_attn(\n",
        "            key=enc_feature,\n",
        "            value=enc_feature,\n",
        "            query=tgt_feature,\n",
        "            mask=enc_tgt_mask)\n",
        "        tgt_feature = self.dropout(tgt_feature) + residual\n",
        "\n",
        "        #################################################\n",
        "        # FFW\n",
        "        #################################################\n",
        "        residual = tgt_feature\n",
        "        tgt_feature = apply_norm(self.norm_ffw, tgt_feature)\n",
        "        tgt_feature = self.ffw(tgt_feature)\n",
        "        tgt_feature = self.dropout(tgt_feature) + residual\n",
        "        return tgt_feature\n",
        "\n",
        "    def _forward_postnorm(self,\n",
        "                          tgt_feature,\n",
        "                          enc_feature,\n",
        "                          tgt_san_mask,\n",
        "                          enc_tgt_mask):\n",
        "        \"\"\"Post-normalization structure (standard).\n",
        "\n",
        "        \"\"\"\n",
        "        #################################################\n",
        "        # self-attention\n",
        "        #################################################\n",
        "        residual = tgt_feature\n",
        "        tgt_feature, self.sattw = self.self_attn(\n",
        "            key=tgt_feature,\n",
        "            value=tgt_feature,\n",
        "            query=tgt_feature,\n",
        "            mask=tgt_san_mask)\n",
        "        tgt_feature = self.dropout(tgt_feature) + residual\n",
        "        tgt_feature = apply_norm(self.norm_sattn, tgt_feature)\n",
        "\n",
        "        #################################################\n",
        "        # cross-attention\n",
        "        #################################################\n",
        "        residual = tgt_feature\n",
        "        tgt_feature, self.cattw = self.cross_attn(\n",
        "            key=enc_feature,\n",
        "            value=enc_feature,\n",
        "            query=tgt_feature,\n",
        "            mask=enc_tgt_mask)\n",
        "        tgt_feature = self.dropout(tgt_feature) + residual\n",
        "        tgt_feature = apply_norm(self.norm_cattn, tgt_feature)\n",
        "\n",
        "        #################################################\n",
        "        # FFW\n",
        "        #################################################\n",
        "        residual = tgt_feature\n",
        "        tgt_feature = self.ffw(tgt_feature)\n",
        "        tgt_feature = self.dropout(tgt_feature) + residual\n",
        "        tgt_feature = apply_norm(self.norm_ffw, tgt_feature)\n",
        "\n",
        "        return tgt_feature\n",
        "\n",
        "    def forward(self,\n",
        "                tgt_feature,\n",
        "                enc_feature,\n",
        "                tgt_causal_mask=None,\n",
        "                enc_tgt_causal_mask=None,\n",
        "                tgt_key_padding_mask=None,\n",
        "                enc_key_padding_mask=None):\n",
        "\n",
        "        # Create mask.\n",
        "        if tgt_key_padding_mask is None:\n",
        "            tgt_key_padding_mask = torch.ones(tgt_feature.shape[:2],\n",
        "                                              dtype=enc_feature.dtype,\n",
        "                                              device=enc_feature.device)\n",
        "        tgt_san_mask = make_san_mask(tgt_key_padding_mask, tgt_causal_mask)\n",
        "        if enc_key_padding_mask is None:\n",
        "            enc_key_padding_mask = torch.ones(enc_feature.shape[:2],\n",
        "                                              dtype=enc_feature.dtype,\n",
        "                                              device=enc_feature.device)\n",
        "        enc_tgt_mask = enc_key_padding_mask.unsqueeze(1).repeat(\n",
        "            [1, tgt_feature.shape[1], 1])\n",
        "        if enc_tgt_causal_mask is not None:\n",
        "            enc_tgt_mask = enc_tgt_mask & enc_tgt_causal_mask\n",
        "\n",
        "        if self.norm_first:\n",
        "            tgt_feature = self._forward_prenorm(tgt_feature, enc_feature,\n",
        "                                                tgt_san_mask, enc_tgt_mask)\n",
        "        else:\n",
        "            tgt_feature = self._forward_postnorm(tgt_feature, enc_feature,\n",
        "                                                 tgt_san_mask, enc_tgt_mask)\n",
        "\n",
        "        return tgt_feature"
      ],
      "metadata": {
        "id": "O6r75uRR_-B0"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerDecoder(nn.Module):\n",
        "    def __init__(self,\n",
        "                 decoder_layer,\n",
        "                 out_channels,\n",
        "                 num_layers,\n",
        "                 dim_model,\n",
        "                 dropout_pe,\n",
        "                 norm_type_tail,\n",
        "                 norm_eps,\n",
        "                 norm_first,\n",
        "                 add_bias,\n",
        "                 add_tailnorm,\n",
        "                 padding_val):\n",
        "        super().__init__()\n",
        "\n",
        "        self.emb_layer = nn.Embedding(out_channels,\n",
        "                                      dim_model,\n",
        "                                      padding_idx=padding_val)\n",
        "        self.vocab_size = out_channels\n",
        "\n",
        "        self.pos_encoder = PositionalEncoding(dim_model, dropout_pe)\n",
        "        self.layers = nn.ModuleList([copy.deepcopy(decoder_layer) for _ in range(num_layers)])\n",
        "\n",
        "        # Add LayerNorm at tail position.\n",
        "        # This is applied only when norm_first is True because\n",
        "        # post-normalization structure includes tail-normalization in encoder\n",
        "        # layers.\n",
        "        if add_tailnorm and norm_first:\n",
        "            self.norm_tail = create_norm(norm_type_tail, dim_model, norm_eps, add_bias)\n",
        "        else:\n",
        "            self.norm_tail = Identity()\n",
        "\n",
        "        self.head = nn.Linear(dim_model, out_channels)\n",
        "\n",
        "        self.reset_parameters(dim_model, padding_val)\n",
        "\n",
        "    def reset_parameters(self, embedding_dim, padding_val):\n",
        "        # Bellow initialization has strong effect to performance.\n",
        "        # Please refer.\n",
        "        # https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer/transformer_base.py#L189\n",
        "        nn.init.normal_(self.emb_layer.weight, mean=0, std=embedding_dim**-0.5)\n",
        "        nn.init.constant_(self.emb_layer.weight[padding_val], 0)\n",
        "\n",
        "        # Please refer.\n",
        "        # https://github.com/facebookresearch/fairseq/blob/main/fairseq/models/transformer/transformer_decoder.py\n",
        "        nn.init.xavier_uniform_(self.head.weight)\n",
        "        nn.init.constant_(self.head.bias, 0.0)\n",
        "\n",
        "    def forward(self,\n",
        "                tgt_feature,\n",
        "                enc_feature,\n",
        "                tgt_causal_mask,\n",
        "                enc_tgt_causal_mask,\n",
        "                tgt_key_padding_mask,\n",
        "                enc_key_padding_mask):\n",
        "\n",
        "        tgt_feature = self.emb_layer(tgt_feature) * math.sqrt(self.vocab_size)\n",
        "\n",
        "        tgt_feature = self.pos_encoder(tgt_feature)\n",
        "        for layer in self.layers:\n",
        "            tgt_feature = layer(\n",
        "                tgt_feature=tgt_feature,\n",
        "                enc_feature=enc_feature,\n",
        "                tgt_causal_mask=tgt_causal_mask,\n",
        "                enc_tgt_causal_mask=enc_tgt_causal_mask,\n",
        "                tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "                enc_key_padding_mask=enc_key_padding_mask)\n",
        "        tgt_feature = apply_norm(self.norm_tail, tgt_feature)\n",
        "\n",
        "        logit = self.head(tgt_feature)\n",
        "        return logit"
      ],
      "metadata": {
        "id": "tZ0nKRbMAJhr"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Transformer CSIR model"
      ],
      "metadata": {
        "id": "IpHlCcuGAMbT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerCSLR(nn.Module):\n",
        "    def __init__(self,\n",
        "                 in_channels,\n",
        "                 inter_channels,\n",
        "                 out_channels,\n",
        "                 padding_val,\n",
        "                 activation=\"relu\",\n",
        "                 tren_num_layers=1,\n",
        "                 tren_num_heads=1,\n",
        "                 tren_dim_ffw=256,\n",
        "                 tren_dropout_pe=0.1,\n",
        "                 tren_dropout=0.1,\n",
        "                 tren_norm_type_sattn=\"layer\",\n",
        "                 tren_norm_type_ffw=\"layer\",\n",
        "                 tren_norm_type_tail=\"layer\",\n",
        "                 tren_norm_eps=1e-5,\n",
        "                 tren_norm_first=True,\n",
        "                 tren_add_bias=True,\n",
        "                 tren_add_tailnorm=True,\n",
        "                 trde_num_layers=1,\n",
        "                 trde_num_heads=1,\n",
        "                 trde_dim_ffw=256,\n",
        "                 trde_dropout_pe=0.1,\n",
        "                 trde_dropout=0.1,\n",
        "                 trde_norm_type_sattn=\"layer\",\n",
        "                 trde_norm_type_cattn=\"layer\",\n",
        "                 trde_norm_type_ffw=\"layer\",\n",
        "                 trde_norm_type_tail=\"layer\",\n",
        "                 trde_norm_eps=1e-5,\n",
        "                 trde_norm_first=True,\n",
        "                 trde_add_bias=True,\n",
        "                 trde_add_tailnorm=True):\n",
        "        super().__init__()\n",
        "\n",
        "        # Feature extraction.\n",
        "        self.linear = nn.Linear(in_channels, inter_channels)\n",
        "        self.activation = select_reluwise_activation(activation)\n",
        "\n",
        "        # Transformer-Encoder.\n",
        "        enlayer = TransformerEncoderLayer(\n",
        "            dim_model=inter_channels,\n",
        "            num_heads=tren_num_heads,\n",
        "            dim_ffw=tren_dim_ffw,\n",
        "            dropout=tren_dropout,\n",
        "            activation=activation,\n",
        "            norm_type_sattn=tren_norm_type_sattn,\n",
        "            norm_type_ffw=tren_norm_type_ffw,\n",
        "            norm_eps=tren_norm_eps,\n",
        "            norm_first=tren_norm_first,\n",
        "            add_bias=tren_add_bias)\n",
        "        self.tr_encoder = TransformerEncoder(\n",
        "            encoder_layer=enlayer,\n",
        "            num_layers=tren_num_layers,\n",
        "            dim_model=inter_channels,\n",
        "            dropout_pe=tren_dropout_pe,\n",
        "            norm_type_tail=tren_norm_type_tail,\n",
        "            norm_eps=tren_norm_eps,\n",
        "            norm_first=tren_norm_first,\n",
        "            add_bias=tren_add_bias,\n",
        "            add_tailnorm=tren_add_tailnorm)\n",
        "\n",
        "        # Transformer-Decoder.\n",
        "        delayer = TransformerDecoderLayer(\n",
        "            dim_model=inter_channels,\n",
        "            num_heads=trde_num_heads,\n",
        "            dim_ffw=trde_dim_ffw,\n",
        "            dropout=trde_dropout,\n",
        "            activation=activation,\n",
        "            norm_type_sattn=trde_norm_type_sattn,\n",
        "            norm_type_cattn=trde_norm_type_cattn,\n",
        "            norm_type_ffw=trde_norm_type_ffw,\n",
        "            norm_eps=trde_norm_eps,\n",
        "            norm_first=trde_norm_first,\n",
        "            add_bias=trde_add_bias)\n",
        "        self.tr_decoder = TransformerDecoder(\n",
        "            decoder_layer=delayer,\n",
        "            out_channels=out_channels,\n",
        "            num_layers=trde_num_layers,\n",
        "            dim_model=inter_channels,\n",
        "            dropout_pe=trde_dropout_pe,\n",
        "            norm_type_tail=trde_norm_type_tail,\n",
        "            norm_eps=trde_norm_eps,\n",
        "            norm_first=trde_norm_first,\n",
        "            add_bias=trde_add_bias,\n",
        "            add_tailnorm=trde_add_tailnorm,\n",
        "            padding_val=padding_val)\n",
        "\n",
        "    def forward(self,\n",
        "                src_feature,\n",
        "                tgt_feature,\n",
        "                src_causal_mask,\n",
        "                src_padding_mask,\n",
        "                tgt_causal_mask,\n",
        "                tgt_padding_mask):\n",
        "        \"\"\"Forward computation for train.\n",
        "        \"\"\"\n",
        "        # Feature extraction.\n",
        "        # `[N, C, T, J] -> [N, T, C, J] -> [N, T, C*J] -> [N, T, C']`\n",
        "        N, C, T, J = src_feature.shape\n",
        "        src_feature = src_feature.permute([0, 2, 1, 3])\n",
        "        src_feature = src_feature.reshape(N, T, -1)\n",
        "\n",
        "        src_feature = self.linear(src_feature)\n",
        "\n",
        "        enc_feature = self.tr_encoder(\n",
        "            feature=src_feature,\n",
        "            causal_mask=src_causal_mask,\n",
        "            src_key_padding_mask=src_padding_mask)\n",
        "\n",
        "        preds = self.tr_decoder(tgt_feature=tgt_feature,\n",
        "                                enc_feature=enc_feature,\n",
        "                                tgt_causal_mask=tgt_causal_mask,\n",
        "                                enc_tgt_causal_mask=None,\n",
        "                                tgt_key_padding_mask=tgt_padding_mask,\n",
        "                                enc_key_padding_mask=src_padding_mask)\n",
        "        # `[N, T, C]`\n",
        "        return preds\n",
        "\n",
        "    def inference(self,\n",
        "                  src_feature,\n",
        "                  start_id,\n",
        "                  end_id,\n",
        "                  src_padding_mask=None,\n",
        "                  max_seqlen=62):\n",
        "        \"\"\"Forward computation for test.\n",
        "        \"\"\"\n",
        "\n",
        "        # Feature extraction.\n",
        "        # `[N, C, T, J] -> [N, T, C, J] -> [N, T, C*J] -> [N, T, C']`\n",
        "        N, C, T, J = src_feature.shape\n",
        "        src_feature = src_feature.permute([0, 2, 1, 3])\n",
        "        src_feature = src_feature.reshape(N, T, -1)\n",
        "\n",
        "        src_feature = self.linear(src_feature)\n",
        "\n",
        "        enc_feature = self.tr_encoder(\n",
        "            feature=src_feature,\n",
        "            causal_mask=None,\n",
        "            src_key_padding_mask=src_padding_mask)\n",
        "\n",
        "        # Apply decoder.\n",
        "        dec_inputs = torch.tensor([start_id]).to(src_feature.device)\n",
        "        # `[N, T]`\n",
        "        dec_inputs = dec_inputs.reshape([1, 1])\n",
        "        preds = None\n",
        "        pred_ids = [start_id]\n",
        "        for _ in range(max_seqlen):\n",
        "            pred = self.tr_decoder(\n",
        "                tgt_feature=dec_inputs,\n",
        "                enc_feature=enc_feature,\n",
        "                tgt_causal_mask=None,\n",
        "                enc_tgt_causal_mask=None,\n",
        "                tgt_key_padding_mask=None,\n",
        "                enc_key_padding_mask=src_padding_mask)\n",
        "            # Extract last prediction.\n",
        "            pred = pred[:, -1:, :]\n",
        "            # `[N, T, C]`\n",
        "            if preds is None:\n",
        "                preds = pred\n",
        "            else:\n",
        "                # Concatenate last elements.\n",
        "                preds = torch.cat([preds, pred], dim=1)\n",
        "\n",
        "            pid = torch.argmax(pred, dim=-1)\n",
        "            dec_inputs = torch.cat([dec_inputs, pid], dim=-1)\n",
        "\n",
        "            pid = pid.reshape([1]).detach().cpu().numpy()[0]\n",
        "            pred_ids.append(int(pid))\n",
        "            if int(pid) == end_id:\n",
        "                break\n",
        "\n",
        "        # `[N, T]`\n",
        "        pred_ids = np.array([pred_ids])\n",
        "        return pred_ids, preds"
      ],
      "metadata": {
        "id": "jVUhbKUUAOk8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Sanity check"
      ],
      "metadata": {
        "id": "nMXYp4-gZVRr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Access check.\n",
        "dataset_dir = Path(\"gafs_dataset_very_small\")\n",
        "files = list(dataset_dir.iterdir())\n",
        "dictionary = [fin for fin in files if \".json\" in fin.name][0]\n",
        "hdf5_files = [fin for fin in files if \".hdf5\" in fin.name]\n",
        "\n",
        "print(dictionary)\n",
        "print(hdf5_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dc19b-2pZXQE",
        "outputId": "9d8a8532-49dc-42cf-faeb-be09fa3a3a26"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "gafs_dataset_very_small/character_to_prediction_index.json\n",
            "[PosixPath('gafs_dataset_very_small/6.hdf5'), PosixPath('gafs_dataset_very_small/18.hdf5'), PosixPath('gafs_dataset_very_small/0.hdf5'), PosixPath('gafs_dataset_very_small/74.hdf5'), PosixPath('gafs_dataset_very_small/27.hdf5'), PosixPath('gafs_dataset_very_small/88.hdf5'), PosixPath('gafs_dataset_very_small/71.hdf5'), PosixPath('gafs_dataset_very_small/192.hdf5'), PosixPath('gafs_dataset_very_small/43.hdf5'), PosixPath('gafs_dataset_very_small/143.hdf5'), PosixPath('gafs_dataset_very_small/188.hdf5'), PosixPath('gafs_dataset_very_small/38.hdf5'), PosixPath('gafs_dataset_very_small/109.hdf5'), PosixPath('gafs_dataset_very_small/138.hdf5'), PosixPath('gafs_dataset_very_small/227.hdf5'), PosixPath('gafs_dataset_very_small/230.hdf5'), PosixPath('gafs_dataset_very_small/72.hdf5'), PosixPath('gafs_dataset_very_small/76.hdf5'), PosixPath('gafs_dataset_very_small/168.hdf5'), PosixPath('gafs_dataset_very_small/40.hdf5'), PosixPath('gafs_dataset_very_small/81.hdf5'), PosixPath('gafs_dataset_very_small/236.hdf5'), PosixPath('gafs_dataset_very_small/20.hdf5'), PosixPath('gafs_dataset_very_small/169.hdf5'), PosixPath('gafs_dataset_very_small/187.hdf5'), PosixPath('gafs_dataset_very_small/128.hdf5'), PosixPath('gafs_dataset_very_small/219.hdf5'), PosixPath('gafs_dataset_very_small/89.hdf5'), PosixPath('gafs_dataset_very_small/107.hdf5'), PosixPath('gafs_dataset_very_small/56.hdf5'), PosixPath('gafs_dataset_very_small/202.hdf5'), PosixPath('gafs_dataset_very_small/178.hdf5'), PosixPath('gafs_dataset_very_small/141.hdf5'), PosixPath('gafs_dataset_very_small/53.hdf5'), PosixPath('gafs_dataset_very_small/151.hdf5'), PosixPath('gafs_dataset_very_small/153.hdf5'), PosixPath('gafs_dataset_very_small/112.hdf5'), PosixPath('gafs_dataset_very_small/125.hdf5'), PosixPath('gafs_dataset_very_small/176.hdf5'), PosixPath('gafs_dataset_very_small/102.hdf5'), PosixPath('gafs_dataset_very_small/242.hdf5'), PosixPath('gafs_dataset_very_small/70.hdf5'), PosixPath('gafs_dataset_very_small/233.hdf5'), PosixPath('gafs_dataset_very_small/181.hdf5'), PosixPath('gafs_dataset_very_small/135.hdf5'), PosixPath('gafs_dataset_very_small/68.hdf5'), PosixPath('gafs_dataset_very_small/105.hdf5'), PosixPath('gafs_dataset_very_small/154.hdf5'), PosixPath('gafs_dataset_very_small/63.hdf5'), PosixPath('gafs_dataset_very_small/239.hdf5'), PosixPath('gafs_dataset_very_small/216.hdf5'), PosixPath('gafs_dataset_very_small/231.hdf5'), PosixPath('gafs_dataset_very_small/93.hdf5'), PosixPath('gafs_dataset_very_small/59.hdf5'), PosixPath('gafs_dataset_very_small/251.hdf5'), PosixPath('gafs_dataset_very_small/145.hdf5'), PosixPath('gafs_dataset_very_small/196.hdf5'), PosixPath('gafs_dataset_very_small/225.hdf5'), PosixPath('gafs_dataset_very_small/217.hdf5'), PosixPath('gafs_dataset_very_small/223.hdf5'), PosixPath('gafs_dataset_very_small/4.hdf5'), PosixPath('gafs_dataset_very_small/117.hdf5'), PosixPath('gafs_dataset_very_small/25.hdf5'), PosixPath('gafs_dataset_very_small/2.hdf5'), PosixPath('gafs_dataset_very_small/136.hdf5'), PosixPath('gafs_dataset_very_small/113.hdf5'), PosixPath('gafs_dataset_very_small/160.hdf5'), PosixPath('gafs_dataset_very_small/21.hdf5'), PosixPath('gafs_dataset_very_small/121.hdf5'), PosixPath('gafs_dataset_very_small/1.hdf5'), PosixPath('gafs_dataset_very_small/95.hdf5'), PosixPath('gafs_dataset_very_small/147.hdf5'), PosixPath('gafs_dataset_very_small/36.hdf5'), PosixPath('gafs_dataset_very_small/157.hdf5'), PosixPath('gafs_dataset_very_small/73.hdf5'), PosixPath('gafs_dataset_very_small/15.hdf5'), PosixPath('gafs_dataset_very_small/158.hdf5'), PosixPath('gafs_dataset_very_small/241.hdf5'), PosixPath('gafs_dataset_very_small/161.hdf5'), PosixPath('gafs_dataset_very_small/254.hdf5'), PosixPath('gafs_dataset_very_small/10.hdf5'), PosixPath('gafs_dataset_very_small/203.hdf5'), PosixPath('gafs_dataset_very_small/115.hdf5'), PosixPath('gafs_dataset_very_small/24.hdf5'), PosixPath('gafs_dataset_very_small/9.hdf5'), PosixPath('gafs_dataset_very_small/92.hdf5'), PosixPath('gafs_dataset_very_small/246.hdf5'), PosixPath('gafs_dataset_very_small/13.hdf5'), PosixPath('gafs_dataset_very_small/80.hdf5'), PosixPath('gafs_dataset_very_small/122.hdf5'), PosixPath('gafs_dataset_very_small/186.hdf5'), PosixPath('gafs_dataset_very_small/171.hdf5')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dictionary.\n",
        "with open(dictionary, \"r\") as fread:\n",
        "    key2token = json.load(fread)\n",
        "\n",
        "VOCAB = len(key2token)\n",
        "# Add keywords.\n",
        "key2token[\"<sos>\"] = VOCAB\n",
        "key2token[\"<eos>\"] = VOCAB + 1\n",
        "key2token[\"<pad>\"] = VOCAB + 2\n",
        "# Reset.\n",
        "VOCAB = len(key2token)"
      ],
      "metadata": {
        "id": "BPoxLXpDZchs"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "_, use_landmarks = get_fullbody_landmarks()\n",
        "use_features = [\"x\", \"y\"]\n",
        "\n",
        "trans_select_feature = SelectLandmarksAndFeature(landmarks=use_landmarks, features=use_features)\n",
        "trans_repnan = ReplaceNan()\n",
        "trans_norm = PartsBasedNormalization(align_mode=\"framewise\", scale_mode=\"unique\")\n",
        "trans_insert_token = InsertTokensForS2S(sos_token=key2token[\"<sos>\"], eos_token=key2token[\"<eos>\"])\n",
        "\n",
        "pre_transforms = Compose([\n",
        "    trans_select_feature,\n",
        "    trans_repnan,\n",
        "    trans_insert_token,\n",
        "    trans_norm\n",
        "])\n",
        "\n",
        "train_transforms = Compose([\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "val_transforms = Compose([\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "test_transforms = Compose([\n",
        "    ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "I6KEUSeqZf2U"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 2\n",
        "feature_shape = (len(use_features), -1, len(use_landmarks))\n",
        "token_shape = (-1,)\n",
        "merge_fn = partial(merge_padded_batch,\n",
        "                   feature_shape=feature_shape,\n",
        "                   token_shape=token_shape,\n",
        "                   feature_padding_val=0.0,\n",
        "                   token_padding_val=key2token[\"<pad>\"])\n",
        "\n",
        "dataset = HDF5Dataset(hdf5_files, pre_transforms=pre_transforms, transforms=train_transforms)\n",
        "\n",
        "dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=merge_fn)\n",
        "try:\n",
        "    data = next(iter(dataloader))\n",
        "    feature_origin = data[\"feature\"]\n",
        "    tokens_origin = data[\"token\"]\n",
        "\n",
        "    print(feature_origin.shape)\n",
        "    print(tokens_origin)\n",
        "except Exception as inst:\n",
        "    print(inst)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rExP4cCiGAm",
        "outputId": "cd413d26-1513-40d9-dd02-24f84bf44baa"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2, 409, 130])\n",
            "tensor([[59, 10, 24, 24, 20, 12, 19, 17, 22, 16, 12, 23, 19, 22, 16, 20, 60, 61,\n",
            "         61, 61, 61, 61, 61, 61],\n",
            "        [59, 10, 19, 16, 12, 21, 24, 12, 24, 17, 20, 12, 16, 15, 12, 20, 23, 12,\n",
            "         24, 19, 16, 22, 24, 60]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define model.\n",
        "# in_channels: J * C (130*2=260)\n",
        "#   J: use_landmarks (130)\n",
        "#   C: use_channels (2)\n",
        "# out_channels: 10\n",
        "in_channels = len(use_landmarks) * len(use_features)\n",
        "inter_channels = 64\n",
        "out_channels = VOCAB\n",
        "norm_type = \"layer\"\n",
        "pad_token = key2token[\"<pad>\"]\n",
        "model = TransformerCSLR(\n",
        "    in_channels=in_channels,\n",
        "    inter_channels=inter_channels,\n",
        "    out_channels=out_channels,\n",
        "    padding_val=pad_token,\n",
        "    activation=\"relu\",\n",
        "    tren_num_layers=2,\n",
        "    tren_num_heads=2,\n",
        "    tren_dim_ffw=256,\n",
        "    tren_dropout_pe=0.1,\n",
        "    tren_dropout=0.1,\n",
        "    tren_norm_type_sattn=norm_type,\n",
        "    tren_norm_type_ffw=norm_type,\n",
        "    tren_norm_type_tail=norm_type,\n",
        "    tren_norm_eps=1e-5,\n",
        "    tren_norm_first=True,\n",
        "    tren_add_bias=True,\n",
        "    tren_add_tailnorm=True,\n",
        "    trde_num_layers=2,\n",
        "    trde_num_heads=2,\n",
        "    trde_dim_ffw=256,\n",
        "    trde_dropout_pe=0.1,\n",
        "    trde_dropout=0.1,\n",
        "    trde_norm_type_sattn=norm_type,\n",
        "    trde_norm_type_cattn=norm_type,\n",
        "    trde_norm_type_ffw=norm_type,\n",
        "    trde_norm_type_tail=norm_type,\n",
        "    trde_norm_eps=1e-5,\n",
        "    trde_norm_first=True,\n",
        "    trde_add_bias=True,\n",
        "    trde_add_tailnorm=True)\n",
        "\n",
        "print(model)\n",
        "\n",
        "# Sanity check.\n",
        "sample = next(iter(dataloader))\n",
        "logit = model(src_feature=sample[\"feature\"],\n",
        "              tgt_feature=sample[\"token\"],\n",
        "              src_causal_mask=None,\n",
        "              src_padding_mask=sample[\"feature_pad_mask\"],\n",
        "              tgt_causal_mask=make_causal_mask(sample[\"token_pad_mask\"]),\n",
        "              tgt_padding_mask=sample[\"token_pad_mask\"])\n",
        "print(logit.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1yQKHqQtiUTE",
        "outputId": "66b26e58-75c4-4fc5-8cd5-123b1fe8cc7f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerCSLR(\n",
            "  (linear): Linear(in_features=260, out_features=64, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (tr_encoder): TransformerEncoder(\n",
            "    (pos_encoder): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (w_key): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_value): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_query): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (dropout_attn): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (norm_sattn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (ffw): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=64, out_features=256, bias=True)\n",
            "          (w_2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (norm_ffw): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm_tail): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (tr_decoder): TransformerDecoder(\n",
            "    (emb_layer): Embedding(62, 64, padding_idx=61)\n",
            "    (pos_encoder): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (w_key): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_value): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_query): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (dropout_attn): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (norm_sattn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (cross_attn): MultiheadAttention(\n",
            "          (w_key): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_value): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_query): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (dropout_attn): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (norm_cattn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (ffw): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=64, out_features=256, bias=True)\n",
            "          (w_2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (norm_ffw): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm_tail): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (head): Linear(in_features=64, out_features=62, bias=True)\n",
            "  )\n",
            ")\n",
            "torch.Size([2, 24, 62])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Train and evaluation"
      ],
      "metadata": {
        "id": "r4o9bbOMjG_b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.1 Set common parameters"
      ],
      "metadata": {
        "id": "22_3Ne9ojKLD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Set common parameters.\n",
        "batch_size = 32\n",
        "load_into_ram = True\n",
        "test_pid = 0\n",
        "num_workers = os.cpu_count()\n",
        "print(f\"Using {num_workers} cores for data loading.\")\n",
        "lr = 3e-4\n",
        "label_smoothing = 0.1\n",
        "sos_token = key2token[\"<sos>\"]\n",
        "eos_token = key2token[\"<eos>\"]\n",
        "pad_token = key2token[\"<pad>\"]\n",
        "max_seqlen = 60\n",
        "\n",
        "epochs = 50\n",
        "eval_every_n_epochs = 1\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using {device} for computation.\")\n",
        "\n",
        "train_hdf5files = [fin for fin in hdf5_files if str(test_pid) not in fin.name]\n",
        "val_hdf5files = [fin for fin in hdf5_files if str(test_pid) in fin.name]\n",
        "test_hdf5files = [fin for fin in hdf5_files if str(test_pid) in fin.name]\n",
        "\n",
        "_, use_landmarks = get_fullbody_landmarks()\n",
        "use_features = [\"x\", \"y\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3UpkewijNd0",
        "outputId": "a42d9d87-92a0-44e3-8075-b84eb9de506a"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using 2 cores for data loading.\n",
            "Using cuda for computation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Build dataloaders.\n",
        "train_dataset = HDF5Dataset(train_hdf5files,\n",
        "    pre_transforms=pre_transforms, transforms=train_transforms, load_into_ram=load_into_ram)\n",
        "val_dataset = HDF5Dataset(val_hdf5files,\n",
        "    pre_transforms=pre_transforms, transforms=val_transforms, load_into_ram=load_into_ram)\n",
        "test_dataset = HDF5Dataset(test_hdf5files,\n",
        "    pre_transforms=pre_transforms, transforms=test_transforms, load_into_ram=load_into_ram)\n",
        "\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, collate_fn=merge_fn, num_workers=num_workers, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, collate_fn=merge_fn, num_workers=num_workers, shuffle=False)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=1, collate_fn=merge_fn, num_workers=num_workers, shuffle=False)"
      ],
      "metadata": {
        "id": "RiTJhuSSjW8k"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.2 Run training process"
      ],
      "metadata": {
        "id": "idjHfhW4jerd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_transformer = TransformerCSLR(\n",
        "    in_channels=in_channels,\n",
        "    inter_channels=inter_channels,\n",
        "    out_channels=out_channels,\n",
        "    padding_val=pad_token,\n",
        "    activation=\"relu\",\n",
        "    tren_num_layers=2,\n",
        "    tren_num_heads=2,\n",
        "    tren_dim_ffw=256,\n",
        "    tren_dropout_pe=0.1,\n",
        "    tren_dropout=0.1,\n",
        "    tren_norm_type_sattn=norm_type,\n",
        "    tren_norm_type_ffw=norm_type,\n",
        "    tren_norm_type_tail=norm_type,\n",
        "    tren_norm_eps=1e-5,\n",
        "    tren_norm_first=True,\n",
        "    tren_add_bias=True,\n",
        "    tren_add_tailnorm=True,\n",
        "    trde_num_layers=2,\n",
        "    trde_num_heads=2,\n",
        "    trde_dim_ffw=256,\n",
        "    trde_dropout_pe=0.1,\n",
        "    trde_dropout=0.1,\n",
        "    trde_norm_type_sattn=norm_type,\n",
        "    trde_norm_type_cattn=norm_type,\n",
        "    trde_norm_type_ffw=norm_type,\n",
        "    trde_norm_type_tail=norm_type,\n",
        "    trde_norm_eps=1e-5,\n",
        "    trde_norm_first=True,\n",
        "    trde_add_bias=True,\n",
        "    trde_add_tailnorm=True)\n",
        "\n",
        "print(model_transformer)\n",
        "\n",
        "loss_fn = LabelSmoothingCrossEntropyLoss(\n",
        "    ignore_indices=pad_token, reduction=\"mean_temporal_prior\",\n",
        "    label_smoothing=label_smoothing)\n",
        "optimizer = torch.optim.Adam(model_transformer.parameters(), lr=lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAXnUtz5jheb",
        "outputId": "b45620a7-ee91-4d1e-dec2-d26d8a92805b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TransformerCSLR(\n",
            "  (linear): Linear(in_features=260, out_features=64, bias=True)\n",
            "  (activation): ReLU()\n",
            "  (tr_encoder): TransformerEncoder(\n",
            "    (pos_encoder): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x TransformerEncoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (w_key): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_value): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_query): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (dropout_attn): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (norm_sattn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (ffw): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=64, out_features=256, bias=True)\n",
            "          (w_2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (norm_ffw): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm_tail): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "  )\n",
            "  (tr_decoder): TransformerDecoder(\n",
            "    (emb_layer): Embedding(62, 64, padding_idx=61)\n",
            "    (pos_encoder): PositionalEncoding(\n",
            "      (dropout): Dropout(p=0.1, inplace=False)\n",
            "    )\n",
            "    (layers): ModuleList(\n",
            "      (0-1): 2 x TransformerDecoderLayer(\n",
            "        (self_attn): MultiheadAttention(\n",
            "          (w_key): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_value): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_query): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (dropout_attn): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (norm_sattn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (cross_attn): MultiheadAttention(\n",
            "          (w_key): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_value): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_query): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (w_out): Linear(in_features=64, out_features=64, bias=True)\n",
            "          (dropout_attn): Dropout(p=0.1, inplace=False)\n",
            "        )\n",
            "        (norm_cattn): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (ffw): PositionwiseFeedForward(\n",
            "          (w_1): Linear(in_features=64, out_features=256, bias=True)\n",
            "          (w_2): Linear(in_features=256, out_features=64, bias=True)\n",
            "          (dropout): Dropout(p=0.1, inplace=False)\n",
            "          (activation): ReLU()\n",
            "        )\n",
            "        (norm_ffw): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "        (dropout): Dropout(p=0.1, inplace=False)\n",
            "      )\n",
            "    )\n",
            "    (norm_tail): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
            "    (head): Linear(in_features=64, out_features=62, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train, validation, and evaluation.\n",
        "model_transformer.to(device)\n",
        "\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "test_wers = []\n",
        "print(\"Start training.\")\n",
        "for epoch in range(epochs):\n",
        "    print(\"-\" * 80)\n",
        "    print(f\"Epoch {epoch+1}\")\n",
        "\n",
        "    train_loss, train_times = train_loop_csir_s2s(\n",
        "        train_dataloader, model_transformer, loss_fn, optimizer, device,\n",
        "        sos_token, eos_token,\n",
        "        return_pred_times=True)\n",
        "    val_loss, val_times = val_loop_csir_s2s(\n",
        "        val_dataloader, model_transformer, loss_fn, device,\n",
        "        sos_token, eos_token,\n",
        "        return_pred_times=True)\n",
        "    val_losses.append(val_loss)\n",
        "\n",
        "    if (epoch+1) % eval_every_n_epochs == 0:\n",
        "        wer, test_times = test_loop_csir_s2s(\n",
        "            test_dataloader, model_transformer, device,\n",
        "            sos_token, eos_token,\n",
        "            max_seqlen=max_seqlen,\n",
        "            return_pred_times=True,\n",
        "            verbose_num=0)\n",
        "        test_wers.append(wer)\n",
        "train_losses_trans = np.array(train_losses)\n",
        "val_losses_trans = np.array(val_losses)\n",
        "test_wers_trans = np.array(test_wers)\n",
        "\n",
        "val_losses_trans = np.array(val_losses_trans)\n",
        "test_wers_trans = np.array(test_wers_trans)\n",
        "print(f\"Minimum validation loss:{val_losses_trans.min()} at {np.argmin(val_losses_trans)+1} epoch.\")\n",
        "print(f\"Minimum WER:{test_wers_trans.min()} at {np.argmin(test_wers_trans)*eval_every_n_epochs+1} epoch.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OSxf_6kBjzAk",
        "outputId": "61ff45d8-25d3-41f3-8238-d4e0a8d8ba1a"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Start training.\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 1\n",
            "Start training.\n",
            "loss:4.439333 [    0/ 2513]\n",
            "Done. Time:9.448199940999984\n",
            "Training performance: \n",
            " Avg loss:3.754940\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9230936449999945\n",
            "Validation performance: \n",
            " Avg loss:3.481351\n",
            "\n",
            "Start test.\n",
            "Done. Time:45.93940524999999\n",
            "Test performance: \n",
            " Avg WER:112.0%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 2\n",
            "Start training.\n",
            "loss:3.436004 [    0/ 2513]\n",
            "Done. Time:8.502622326999983\n",
            "Training performance: \n",
            " Avg loss:3.345483\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9797914130000436\n",
            "Validation performance: \n",
            " Avg loss:3.231443\n",
            "\n",
            "Start test.\n",
            "Done. Time:72.01558895999995\n",
            "Test performance: \n",
            " Avg WER:145.6%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 3\n",
            "Start training.\n",
            "loss:3.249913 [    0/ 2513]\n",
            "Done. Time:6.83921814200005\n",
            "Training performance: \n",
            " Avg loss:3.179837\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.0163386750000427\n",
            "Validation performance: \n",
            " Avg loss:3.108988\n",
            "\n",
            "Start test.\n",
            "Done. Time:37.24182578800003\n",
            "Test performance: \n",
            " Avg WER:94.6%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 4\n",
            "Start training.\n",
            "loss:3.176544 [    0/ 2513]\n",
            "Done. Time:6.571998318999931\n",
            "Training performance: \n",
            " Avg loss:3.090974\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9578306810000186\n",
            "Validation performance: \n",
            " Avg loss:3.044097\n",
            "\n",
            "Start test.\n",
            "Done. Time:37.803288280999936\n",
            "Test performance: \n",
            " Avg WER:95.1%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 5\n",
            "Start training.\n",
            "loss:3.011948 [    0/ 2513]\n",
            "Done. Time:7.12190642500002\n",
            "Training performance: \n",
            " Avg loss:3.035150\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.511016576999964\n",
            "Validation performance: \n",
            " Avg loss:3.004573\n",
            "\n",
            "Start test.\n",
            "Done. Time:35.67956239200009\n",
            "Test performance: \n",
            " Avg WER:94.2%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 6\n",
            "Start training.\n",
            "loss:2.996983 [    0/ 2513]\n",
            "Done. Time:7.687818633999996\n",
            "Training performance: \n",
            " Avg loss:2.998789\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.2693990470000927\n",
            "Validation performance: \n",
            " Avg loss:2.972400\n",
            "\n",
            "Start test.\n",
            "Done. Time:36.32447387000002\n",
            "Test performance: \n",
            " Avg WER:94.6%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 7\n",
            "Start training.\n",
            "loss:2.989534 [    0/ 2513]\n",
            "Done. Time:8.27328971999998\n",
            "Training performance: \n",
            " Avg loss:2.971436\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9846980139999459\n",
            "Validation performance: \n",
            " Avg loss:2.951619\n",
            "\n",
            "Start test.\n",
            "Done. Time:38.06561229099998\n",
            "Test performance: \n",
            " Avg WER:94.6%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 8\n",
            "Start training.\n",
            "loss:2.985688 [    0/ 2513]\n",
            "Done. Time:8.220690537999985\n",
            "Training performance: \n",
            " Avg loss:2.945935\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9902861580000035\n",
            "Validation performance: \n",
            " Avg loss:2.930305\n",
            "\n",
            "Start test.\n",
            "Done. Time:41.49286291200008\n",
            "Test performance: \n",
            " Avg WER:95.6%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 9\n",
            "Start training.\n",
            "loss:2.812426 [    0/ 2513]\n",
            "Done. Time:6.664480277000052\n",
            "Training performance: \n",
            " Avg loss:2.924859\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.531787998000027\n",
            "Validation performance: \n",
            " Avg loss:2.906171\n",
            "\n",
            "Start test.\n",
            "Done. Time:45.283181944000034\n",
            "Test performance: \n",
            " Avg WER:95.7%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 10\n",
            "Start training.\n",
            "loss:2.937754 [    0/ 2513]\n",
            "Done. Time:6.599813524000069\n",
            "Training performance: \n",
            " Avg loss:2.904157\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9881432489999042\n",
            "Validation performance: \n",
            " Avg loss:2.887671\n",
            "\n",
            "Start test.\n",
            "Done. Time:44.850735509999936\n",
            "Test performance: \n",
            " Avg WER:93.3%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 11\n",
            "Start training.\n",
            "loss:2.826433 [    0/ 2513]\n",
            "Done. Time:8.390795443000002\n",
            "Training performance: \n",
            " Avg loss:2.885158\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9671490709999944\n",
            "Validation performance: \n",
            " Avg loss:2.870524\n",
            "\n",
            "Start test.\n",
            "Done. Time:44.75328196400005\n",
            "Test performance: \n",
            " Avg WER:92.9%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 12\n",
            "Start training.\n",
            "loss:2.931400 [    0/ 2513]\n",
            "Done. Time:6.9384686729999885\n",
            "Training performance: \n",
            " Avg loss:2.862003\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.598822107999922\n",
            "Validation performance: \n",
            " Avg loss:2.848968\n",
            "\n",
            "Start test.\n",
            "Done. Time:48.59787495899991\n",
            "Test performance: \n",
            " Avg WER:92.9%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 13\n",
            "Start training.\n",
            "loss:2.823562 [    0/ 2513]\n",
            "Done. Time:7.386541002000058\n",
            "Training performance: \n",
            " Avg loss:2.844967\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.577197852999916\n",
            "Validation performance: \n",
            " Avg loss:2.834103\n",
            "\n",
            "Start test.\n",
            "Done. Time:49.741022180999835\n",
            "Test performance: \n",
            " Avg WER:92.9%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 14\n",
            "Start training.\n",
            "loss:2.828331 [    0/ 2513]\n",
            "Done. Time:8.081129460000056\n",
            "Training performance: \n",
            " Avg loss:2.826970\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.0419282640000347\n",
            "Validation performance: \n",
            " Avg loss:2.817499\n",
            "\n",
            "Start test.\n",
            "Done. Time:45.3053358059999\n",
            "Test performance: \n",
            " Avg WER:88.9%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 15\n",
            "Start training.\n",
            "loss:2.740581 [    0/ 2513]\n",
            "Done. Time:6.544979414000181\n",
            "Training performance: \n",
            " Avg loss:2.811607\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.3833692839998548\n",
            "Validation performance: \n",
            " Avg loss:2.801479\n",
            "\n",
            "Start test.\n",
            "Done. Time:52.051753295000026\n",
            "Test performance: \n",
            " Avg WER:94.3%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 16\n",
            "Start training.\n",
            "loss:2.845178 [    0/ 2513]\n",
            "Done. Time:7.085526110000046\n",
            "Training performance: \n",
            " Avg loss:2.797336\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.525974308000059\n",
            "Validation performance: \n",
            " Avg loss:2.801178\n",
            "\n",
            "Start test.\n",
            "Done. Time:48.97689943499995\n",
            "Test performance: \n",
            " Avg WER:90.5%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 17\n",
            "Start training.\n",
            "loss:2.778097 [    0/ 2513]\n",
            "Done. Time:7.899979065000025\n",
            "Training performance: \n",
            " Avg loss:2.779477\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.0848110520000773\n",
            "Validation performance: \n",
            " Avg loss:2.778161\n",
            "\n",
            "Start test.\n",
            "Done. Time:48.41390725899987\n",
            "Test performance: \n",
            " Avg WER:88.2%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 18\n",
            "Start training.\n",
            "loss:2.659857 [    0/ 2513]\n",
            "Done. Time:7.94796946800011\n",
            "Training performance: \n",
            " Avg loss:2.764070\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.1229551039998569\n",
            "Validation performance: \n",
            " Avg loss:2.761852\n",
            "\n",
            "Start test.\n",
            "Done. Time:49.82301472899985\n",
            "Test performance: \n",
            " Avg WER:89.5%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 19\n",
            "Start training.\n",
            "loss:2.674221 [    0/ 2513]\n",
            "Done. Time:8.172405702000106\n",
            "Training performance: \n",
            " Avg loss:2.746720\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9986154020000413\n",
            "Validation performance: \n",
            " Avg loss:2.751047\n",
            "\n",
            "Start test.\n",
            "Done. Time:44.165657869999905\n",
            "Test performance: \n",
            " Avg WER:86.3%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 20\n",
            "Start training.\n",
            "loss:2.709248 [    0/ 2513]\n",
            "Done. Time:6.595100453999976\n",
            "Training performance: \n",
            " Avg loss:2.732607\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.3722082000001592\n",
            "Validation performance: \n",
            " Avg loss:2.741151\n",
            "\n",
            "Start test.\n",
            "Done. Time:47.435519457000055\n",
            "Test performance: \n",
            " Avg WER:86.2%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 21\n",
            "Start training.\n",
            "loss:2.785290 [    0/ 2513]\n",
            "Done. Time:6.638951299999917\n",
            "Training performance: \n",
            " Avg loss:2.718239\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.0011795220000295\n",
            "Validation performance: \n",
            " Avg loss:2.731513\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.36415423099993\n",
            "Test performance: \n",
            " Avg WER:87.2%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 22\n",
            "Start training.\n",
            "loss:2.748812 [    0/ 2513]\n",
            "Done. Time:6.423781113999894\n",
            "Training performance: \n",
            " Avg loss:2.705868\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9943629829999736\n",
            "Validation performance: \n",
            " Avg loss:2.721152\n",
            "\n",
            "Start test.\n",
            "Done. Time:48.85966512499999\n",
            "Test performance: \n",
            " Avg WER:86.7%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 23\n",
            "Start training.\n",
            "loss:2.776984 [    0/ 2513]\n",
            "Done. Time:6.5222339070001\n",
            "Training performance: \n",
            " Avg loss:2.691752\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9708841029998894\n",
            "Validation performance: \n",
            " Avg loss:2.720096\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.9472990029999\n",
            "Test performance: \n",
            " Avg WER:87.5%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 24\n",
            "Start training.\n",
            "loss:2.679084 [    0/ 2513]\n",
            "Done. Time:6.598493823999888\n",
            "Training performance: \n",
            " Avg loss:2.674666\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9883156089999829\n",
            "Validation performance: \n",
            " Avg loss:2.703011\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.487870703\n",
            "Test performance: \n",
            " Avg WER:86.0%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 25\n",
            "Start training.\n",
            "loss:2.709470 [    0/ 2513]\n",
            "Done. Time:6.592204874000117\n",
            "Training performance: \n",
            " Avg loss:2.662208\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9932449970001471\n",
            "Validation performance: \n",
            " Avg loss:2.701202\n",
            "\n",
            "Start test.\n",
            "Done. Time:48.121550581000065\n",
            "Test performance: \n",
            " Avg WER:84.7%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 26\n",
            "Start training.\n",
            "loss:2.676337 [    0/ 2513]\n",
            "Done. Time:6.6105114409999715\n",
            "Training performance: \n",
            " Avg loss:2.651152\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9631046869999409\n",
            "Validation performance: \n",
            " Avg loss:2.684132\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.93422999099994\n",
            "Test performance: \n",
            " Avg WER:85.1%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 27\n",
            "Start training.\n",
            "loss:2.610226 [    0/ 2513]\n",
            "Done. Time:6.627519584000083\n",
            "Training performance: \n",
            " Avg loss:2.633750\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.0022400089999337\n",
            "Validation performance: \n",
            " Avg loss:2.682008\n",
            "\n",
            "Start test.\n",
            "Done. Time:49.46696953500009\n",
            "Test performance: \n",
            " Avg WER:84.4%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 28\n",
            "Start training.\n",
            "loss:2.570322 [    0/ 2513]\n",
            "Done. Time:6.7588856689999375\n",
            "Training performance: \n",
            " Avg loss:2.629173\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9660781739999038\n",
            "Validation performance: \n",
            " Avg loss:2.675402\n",
            "\n",
            "Start test.\n",
            "Done. Time:49.27954671300017\n",
            "Test performance: \n",
            " Avg WER:84.3%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 29\n",
            "Start training.\n",
            "loss:2.614064 [    0/ 2513]\n",
            "Done. Time:6.616268562999949\n",
            "Training performance: \n",
            " Avg loss:2.613145\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9854030599999533\n",
            "Validation performance: \n",
            " Avg loss:2.661646\n",
            "\n",
            "Start test.\n",
            "Done. Time:49.55807903800019\n",
            "Test performance: \n",
            " Avg WER:84.3%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 30\n",
            "Start training.\n",
            "loss:2.574583 [    0/ 2513]\n",
            "Done. Time:6.564266081999904\n",
            "Training performance: \n",
            " Avg loss:2.599932\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9711187900002187\n",
            "Validation performance: \n",
            " Avg loss:2.653163\n",
            "\n",
            "Start test.\n",
            "Done. Time:51.08601682200015\n",
            "Test performance: \n",
            " Avg WER:84.0%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 31\n",
            "Start training.\n",
            "loss:2.552257 [    0/ 2513]\n",
            "Done. Time:6.596041912000146\n",
            "Training performance: \n",
            " Avg loss:2.591539\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9951446449999821\n",
            "Validation performance: \n",
            " Avg loss:2.648056\n",
            "\n",
            "Start test.\n",
            "Done. Time:51.019111232999876\n",
            "Test performance: \n",
            " Avg WER:85.0%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 32\n",
            "Start training.\n",
            "loss:2.586859 [    0/ 2513]\n",
            "Done. Time:6.710800089999793\n",
            "Training performance: \n",
            " Avg loss:2.580823\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.5094967420000103\n",
            "Validation performance: \n",
            " Avg loss:2.638069\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.287493751000056\n",
            "Test performance: \n",
            " Avg WER:83.2%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 33\n",
            "Start training.\n",
            "loss:2.648199 [    0/ 2513]\n",
            "Done. Time:7.295437691999723\n",
            "Training performance: \n",
            " Avg loss:2.562478\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.5983654599999682\n",
            "Validation performance: \n",
            " Avg loss:2.635838\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.03796816100021\n",
            "Test performance: \n",
            " Avg WER:83.3%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 34\n",
            "Start training.\n",
            "loss:2.512405 [    0/ 2513]\n",
            "Done. Time:7.748967980000089\n",
            "Training performance: \n",
            " Avg loss:2.553712\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.0746044120000988\n",
            "Validation performance: \n",
            " Avg loss:2.627328\n",
            "\n",
            "Start test.\n",
            "Done. Time:48.42374178199998\n",
            "Test performance: \n",
            " Avg WER:81.8%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 35\n",
            "Start training.\n",
            "loss:2.480734 [    0/ 2513]\n",
            "Done. Time:7.931647457999588\n",
            "Training performance: \n",
            " Avg loss:2.544450\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.0682229489998463\n",
            "Validation performance: \n",
            " Avg loss:2.627996\n",
            "\n",
            "Start test.\n",
            "Done. Time:49.028924348000146\n",
            "Test performance: \n",
            " Avg WER:82.5%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 36\n",
            "Start training.\n",
            "loss:2.532394 [    0/ 2513]\n",
            "Done. Time:8.212735669999802\n",
            "Training performance: \n",
            " Avg loss:2.540174\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.0815305269998134\n",
            "Validation performance: \n",
            " Avg loss:2.619981\n",
            "\n",
            "Start test.\n",
            "Done. Time:49.64605014500012\n",
            "Test performance: \n",
            " Avg WER:82.5%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 37\n",
            "Start training.\n",
            "loss:2.481367 [    0/ 2513]\n",
            "Done. Time:8.150030222000169\n",
            "Training performance: \n",
            " Avg loss:2.525236\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9755067430000963\n",
            "Validation performance: \n",
            " Avg loss:2.614518\n",
            "\n",
            "Start test.\n",
            "Done. Time:49.500753196000005\n",
            "Test performance: \n",
            " Avg WER:83.3%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 38\n",
            "Start training.\n",
            "loss:2.500940 [    0/ 2513]\n",
            "Done. Time:8.066214876000231\n",
            "Training performance: \n",
            " Avg loss:2.515166\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9593194389999553\n",
            "Validation performance: \n",
            " Avg loss:2.607171\n",
            "\n",
            "Start test.\n",
            "Done. Time:48.18303511300019\n",
            "Test performance: \n",
            " Avg WER:80.8%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 39\n",
            "Start training.\n",
            "loss:2.554028 [    0/ 2513]\n",
            "Done. Time:8.662332262999826\n",
            "Training performance: \n",
            " Avg loss:2.502827\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9783829329999207\n",
            "Validation performance: \n",
            " Avg loss:2.595115\n",
            "\n",
            "Start test.\n",
            "Done. Time:49.047152001000086\n",
            "Test performance: \n",
            " Avg WER:81.6%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 40\n",
            "Start training.\n",
            "loss:2.569690 [    0/ 2513]\n",
            "Done. Time:8.140242087999923\n",
            "Training performance: \n",
            " Avg loss:2.498047\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9761490129999402\n",
            "Validation performance: \n",
            " Avg loss:2.584799\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.15496619500027\n",
            "Test performance: \n",
            " Avg WER:82.1%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 41\n",
            "Start training.\n",
            "loss:2.351980 [    0/ 2513]\n",
            "Done. Time:8.560732996000297\n",
            "Training performance: \n",
            " Avg loss:2.485185\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.955001060000086\n",
            "Validation performance: \n",
            " Avg loss:2.582445\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.70009315700008\n",
            "Test performance: \n",
            " Avg WER:82.5%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 42\n",
            "Start training.\n",
            "loss:2.365631 [    0/ 2513]\n",
            "Done. Time:8.047120556000209\n",
            "Training performance: \n",
            " Avg loss:2.477098\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9856856390001667\n",
            "Validation performance: \n",
            " Avg loss:2.577689\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.19439106500022\n",
            "Test performance: \n",
            " Avg WER:80.0%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 43\n",
            "Start training.\n",
            "loss:2.432103 [    0/ 2513]\n",
            "Done. Time:7.366634771999998\n",
            "Training performance: \n",
            " Avg loss:2.464476\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9660870889997568\n",
            "Validation performance: \n",
            " Avg loss:2.579503\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.32887564800012\n",
            "Test performance: \n",
            " Avg WER:79.2%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 44\n",
            "Start training.\n",
            "loss:2.454885 [    0/ 2513]\n",
            "Done. Time:6.847930256999916\n",
            "Training performance: \n",
            " Avg loss:2.457287\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9648944450000272\n",
            "Validation performance: \n",
            " Avg loss:2.579295\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.785688906999894\n",
            "Test performance: \n",
            " Avg WER:81.1%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 45\n",
            "Start training.\n",
            "loss:2.412571 [    0/ 2513]\n",
            "Done. Time:6.557424131000062\n",
            "Training performance: \n",
            " Avg loss:2.452523\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9589155319999918\n",
            "Validation performance: \n",
            " Avg loss:2.569486\n",
            "\n",
            "Start test.\n",
            "Done. Time:49.808327007000116\n",
            "Test performance: \n",
            " Avg WER:79.6%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 46\n",
            "Start training.\n",
            "loss:2.440516 [    0/ 2513]\n",
            "Done. Time:6.543951182000001\n",
            "Training performance: \n",
            " Avg loss:2.439026\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.016903247999835\n",
            "Validation performance: \n",
            " Avg loss:2.568224\n",
            "\n",
            "Start test.\n",
            "Done. Time:53.02139877899981\n",
            "Test performance: \n",
            " Avg WER:82.4%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 47\n",
            "Start training.\n",
            "loss:2.483615 [    0/ 2513]\n",
            "Done. Time:7.605143534000035\n",
            "Training performance: \n",
            " Avg loss:2.432310\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.25156921100006\n",
            "Validation performance: \n",
            " Avg loss:2.555240\n",
            "\n",
            "Start test.\n",
            "Done. Time:48.45847433300014\n",
            "Test performance: \n",
            " Avg WER:78.1%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 48\n",
            "Start training.\n",
            "loss:2.529837 [    0/ 2513]\n",
            "Done. Time:7.686657033999836\n",
            "Training performance: \n",
            " Avg loss:2.426145\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.1184693139998672\n",
            "Validation performance: \n",
            " Avg loss:2.550396\n",
            "\n",
            "Start test.\n",
            "Done. Time:49.50597743700018\n",
            "Test performance: \n",
            " Avg WER:78.9%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 49\n",
            "Start training.\n",
            "loss:2.285697 [    0/ 2513]\n",
            "Done. Time:7.859044678999908\n",
            "Training performance: \n",
            " Avg loss:2.419839\n",
            "\n",
            "Start validation.\n",
            "Done. Time:1.064733298000192\n",
            "Validation performance: \n",
            " Avg loss:2.548066\n",
            "\n",
            "Start test.\n",
            "Done. Time:50.86084101899996\n",
            "Test performance: \n",
            " Avg WER:80.5%\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "Epoch 50\n",
            "Start training.\n",
            "loss:2.355552 [    0/ 2513]\n",
            "Done. Time:8.153878860000077\n",
            "Training performance: \n",
            " Avg loss:2.408425\n",
            "\n",
            "Start validation.\n",
            "Done. Time:0.9502329120000468\n",
            "Validation performance: \n",
            " Avg loss:2.546397\n",
            "\n",
            "Start test.\n",
            "Done. Time:52.02590661000022\n",
            "Test performance: \n",
            " Avg WER:79.4%\n",
            "\n",
            "Minimum validation loss:2.546396642923355 at 50 epoch.\n",
            "Minimum WER:78.10894972801826 at 47 epoch.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Plot result"
      ],
      "metadata": {
        "id": "bI_5zh65kfss"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.grid(axis=\"y\", linestyle=\"dotted\", color=\"k\")\n",
        "\n",
        "xs = np.arange(1, len(val_losses_trans)+1)\n",
        "plt.plot(xs, val_losses_trans, label=\"Transformer\", marker=\".\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.ylim([0.0, 5.0])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "kQ1seXMDkiHj",
        "outputId": "0b80230f-489b-4306-c94a-a3cfab50807d"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.grid(axis=\"y\", linestyle=\"dotted\", color=\"k\")\n",
        "\n",
        "xs = np.arange(1, len(test_wers_trans)+1)\n",
        "plt.plot(xs, test_wers_trans, label=\"Transformer\", marker=\".\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"WER\")\n",
        "plt.ylim([0.0, 100.0])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 455
        },
        "id": "4Uq2CQVDk9ol",
        "outputId": "6879e13c-45bc-4f6a-bf37-1300894963ed"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}