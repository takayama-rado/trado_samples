{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPIIQK3mHniH+DpvCOLMnWj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takayama-rado/trado_samples/blob/main/colab_files/exp_track_interp_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load library"
      ],
      "metadata": {
        "id": "1a3HS9LJ69qT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wnoKLBpt60HT"
      },
      "outputs": [],
      "source": [
        "# Standard modules.\n",
        "import time\n",
        "\n",
        "# CV/ML.\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load data"
      ],
      "metadata": {
        "id": "DE9T4_xs7KtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6seTTj27MQy",
        "outputId": "766181d9-a89a-4c5a-e8f0-bc976d9c4b76"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-04 02:29:57--  https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static.npy\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static.npy [following]\n",
            "--2023-10-04 02:29:58--  https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300608 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘finger_far0_non_static.npy’\n",
            "\n",
            "finger_far0_non_sta 100%[===================>]   2.19M  10.2MB/s    in 0.2s    \n",
            "\n",
            "2023-10-04 02:29:59 (10.2 MB/s) - ‘finger_far0_non_static.npy’ saved [2300608/2300608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static_interp.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8y0T9ST7OQU",
        "outputId": "e4754a75-e631-43fc-938e-dd55a1c6aff3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-04 02:29:59--  https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static_interp.npy\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static_interp.npy [following]\n",
            "--2023-10-04 02:29:59--  https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static_interp.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300608 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘finger_far0_non_static_interp.npy’\n",
            "\n",
            "finger_far0_non_sta 100%[===================>]   2.19M  9.52MB/s    in 0.2s    \n",
            "\n",
            "2023-10-04 02:30:00 (9.52 MB/s) - ‘finger_far0_non_static_interp.npy’ saved [2300608/2300608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K77KboXc7QkC",
        "outputId": "e47e7635-b28e-42fb-8f11-8de921f0e1e7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finger_far0_non_static_interp.npy  finger_far0_non_static.npy  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Tensorflow implementation"
      ],
      "metadata": {
        "id": "2cj2oAJR7XvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Implementation based on define-by-run (eager execution)"
      ],
      "metadata": {
        "id": "sQAF02d-7asq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_interp_tf_eager(track):\n",
        "    orig_shape = tf.shape(track)\n",
        "    tlength = orig_shape[0]\n",
        "    mask = track[:, 0, -1] != 0\n",
        "    valid = tf.reduce_sum(tf.cast(mask, dtype=tf.int32))\n",
        "    if valid == tlength:\n",
        "        y = track\n",
        "    else:\n",
        "        xs = tf.where(mask)\n",
        "        xs = tf.reshape(xs, [valid])\n",
        "        # determine the output data type\n",
        "        ys = tf.reshape(track, [tlength, -1])\n",
        "        ys = tf.gather(ys, xs, axis=0)\n",
        "        x = tf.range(tlength)\n",
        "        dtype_ys = ys.dtype\n",
        "\n",
        "        # normalize data types\n",
        "        xs = tf.cast(xs, dtype_ys)\n",
        "        x = tf.cast(x, dtype_ys)\n",
        "\n",
        "        # pad control points for extrapolation\n",
        "        xs = tf.concat([[xs.dtype.min], xs, [xs.dtype.max]], axis=0)\n",
        "        ys = tf.concat([ys[:1], ys, ys[-1:]], axis=0)\n",
        "\n",
        "        # compute slopes, pad at the edges to flatten\n",
        "        sloops = (ys[1:] - ys[:-1]) / tf.expand_dims((xs[1:] - xs[:-1]), axis=-1)\n",
        "        sloops = tf.pad(sloops[:-1], [(1, 1), (0, 0)])\n",
        "\n",
        "        # solve for intercepts\n",
        "        intercepts = ys - sloops * tf.expand_dims(xs, axis=-1)\n",
        "\n",
        "        # search for the line parameters at each input data point\n",
        "        # create a grid of the inputs and piece breakpoints for thresholding\n",
        "        # rely on argmax stopping on the first true when there are duplicates,\n",
        "        # which gives us an index into the parameter vectors\n",
        "        idx = tf.math.argmax(tf.expand_dims(xs, axis=-2) > tf.expand_dims(x, axis=-1), axis=-1)\n",
        "        sloop = tf.gather(sloops, idx, axis=0)\n",
        "        intercept = tf.gather(intercepts, idx, axis=0)\n",
        "\n",
        "        # apply the linear mapping at each input data point\n",
        "        y = sloop * tf.expand_dims(x, axis=-1) + intercept\n",
        "        y = tf.cast(y, dtype_ys)\n",
        "        y = tf.reshape(y, orig_shape)\n",
        "    return y\n",
        "\n",
        "\n",
        "def partsbased_interp_tf_eager(trackdata):\n",
        "    num_joints = trackdata.shape[1]\n",
        "    trackdata = tf.convert_to_tensor(trackdata)\n",
        "    pose = tf.gather(trackdata, tf.range(0, 33), axis=1)\n",
        "    lhand = tf.gather(trackdata, tf.range(33, 33+21), axis=1)\n",
        "    rhand = tf.gather(trackdata, tf.range(33+21, 33+21+21), axis=1)\n",
        "    face = tf.gather(trackdata, tf.range(33+21+21, num_joints), axis=1)\n",
        "\n",
        "    pose = matrix_interp_tf_eager(pose)\n",
        "    lhand = matrix_interp_tf_eager(lhand)\n",
        "    rhand = matrix_interp_tf_eager(rhand)\n",
        "    face = matrix_interp_tf_eager(face)\n",
        "    return tf.concat([pose, lhand, rhand, face], axis=1)"
      ],
      "metadata": {
        "id": "c2qyp0Zp7hC6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trackdata = np.load(\"finger_far0_non_static.npy\")\n",
        "reftrack = np.load(\"finger_far0_non_static_interp.npy\")\n",
        "# Remove person axis.\n",
        "trackdata = trackdata[0]\n",
        "reftrack = reftrack[0]"
      ],
      "metadata": {
        "id": "rUR_6HgQJbU2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf_eager(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf_eager(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdouNLEF7nXR",
        "outputId": "1971120b-69f0-4623-d688-77946fd2c5bd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.23627284999999887\n",
            "Average time after second call:0.012475181299999605\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf_eager(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf_eager(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack[:-1] - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiP8savd7ora",
        "outputId": "bbd3a497-94e8-465c-d6a3-526875d5109a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.017960879000000318\n",
            "Average time after second call:0.012832941700000332\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Implementation based on define-and-run (tf.function)"
      ],
      "metadata": {
        "id": "jiXZc_Oo7sTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If input_signature is omitted, the re-tracing is performed when a tensor's shape is changed.\n",
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None, None, 4], dtype=tf.float64),))\n",
        "def matrix_interp_tf(track):\n",
        "    orig_shape = tf.shape(track)\n",
        "    tlength = orig_shape[0]\n",
        "    mask = track[:, 0, -1] != 0\n",
        "    valid = tf.reduce_sum(tf.cast(mask, dtype=tf.int32))\n",
        "    if valid == tlength:\n",
        "        y = track\n",
        "    else:\n",
        "        xs = tf.where(mask)\n",
        "        xs = tf.reshape(xs, [valid])\n",
        "        # determine the output data type\n",
        "        ys = tf.reshape(track, [tlength, -1])\n",
        "        ys = tf.gather(ys, xs, axis=0)\n",
        "        x = tf.range(tlength)\n",
        "        dtype_ys = ys.dtype\n",
        "\n",
        "        # normalize data types\n",
        "        xs = tf.cast(xs, dtype_ys)\n",
        "        x = tf.cast(x, dtype_ys)\n",
        "\n",
        "        # pad control points for extrapolation\n",
        "        xs = tf.concat([[xs.dtype.min], xs, [xs.dtype.max]], axis=0)\n",
        "        ys = tf.concat([ys[:1], ys, ys[-1:]], axis=0)\n",
        "\n",
        "        # compute slopes, pad at the edges to flatten\n",
        "        sloops = (ys[1:] - ys[:-1]) / tf.expand_dims((xs[1:] - xs[:-1]), axis=-1)\n",
        "        sloops = tf.pad(sloops[:-1], [(1, 1), (0, 0)])\n",
        "\n",
        "        # solve for intercepts\n",
        "        intercepts = ys - sloops * tf.expand_dims(xs, axis=-1)\n",
        "\n",
        "        # search for the line parameters at each input data point\n",
        "        # create a grid of the inputs and piece breakpoints for thresholding\n",
        "        # rely on argmax stopping on the first true when there are duplicates,\n",
        "        # which gives us an index into the parameter vectors\n",
        "        idx = tf.math.argmax(tf.expand_dims(xs, axis=-2) > tf.expand_dims(x, axis=-1), axis=-1)\n",
        "        sloop = tf.gather(sloops, idx, axis=0)\n",
        "        intercept = tf.gather(intercepts, idx, axis=0)\n",
        "\n",
        "        # apply the linear mapping at each input data point\n",
        "        y = sloop * tf.expand_dims(x, axis=-1) + intercept\n",
        "        y = tf.cast(y, dtype_ys)\n",
        "        y = tf.reshape(y, orig_shape)\n",
        "    return y\n",
        "\n",
        "\n",
        "def partsbased_interp_tf(trackdata):\n",
        "    num_joints = trackdata.shape[1]\n",
        "    trackdata = tf.convert_to_tensor(trackdata)\n",
        "    pose = tf.gather(trackdata, tf.range(0, 33), axis=1)\n",
        "    lhand = tf.gather(trackdata, tf.range(33, 33+21), axis=1)\n",
        "    rhand = tf.gather(trackdata, tf.range(33+21, 33+21+21), axis=1)\n",
        "    face = tf.gather(trackdata, tf.range(33+21+21, num_joints), axis=1)\n",
        "\n",
        "    pose = matrix_interp_tf(pose)\n",
        "    lhand = matrix_interp_tf(lhand)\n",
        "    rhand = matrix_interp_tf(rhand)\n",
        "    face = matrix_interp_tf(face)\n",
        "    return tf.concat([pose, lhand, rhand, face], axis=1)"
      ],
      "metadata": {
        "id": "4rTmEJoX7w6K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2XLppGLJUqU",
        "outputId": "8e86a95d-4158-412f-ddf1-d1b3a48c257b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.3919227340000049\n",
            "Average time after second call:0.007847853200000542\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack[:-1] - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT4RbjQiJ2It",
        "outputId": "f35332fe-77d1-4ef3-872e-6357ddaaa074"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.009688328999999385\n",
            "Average time after second call:0.006184084700000625\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    }
  ]
}