{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM05mMWuMNGTZXzA5UCchZA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takayama-rado/trado_samples/blob/main/colab_files/exp_track_interp_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load library"
      ],
      "metadata": {
        "id": "1a3HS9LJ69qT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wnoKLBpt60HT"
      },
      "outputs": [],
      "source": [
        "# Standard modules.\n",
        "import time\n",
        "\n",
        "# CV/ML.\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load data"
      ],
      "metadata": {
        "id": "DE9T4_xs7KtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6seTTj27MQy",
        "outputId": "9a993ea2-08bf-4cde-83cd-10b10f41f90c"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-29 10:03:05--  https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static.npy\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static.npy [following]\n",
            "--2023-09-29 10:03:05--  https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300608 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘finger_far0_non_static.npy’\n",
            "\n",
            "finger_far0_non_sta 100%[===================>]   2.19M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-09-29 10:03:06 (27.8 MB/s) - ‘finger_far0_non_static.npy’ saved [2300608/2300608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static_interp.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8y0T9ST7OQU",
        "outputId": "5797c385-6f3f-4524-8069-c665fd72d640"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-09-29 10:03:06--  https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static_interp.npy\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static_interp.npy [following]\n",
            "--2023-09-29 10:03:06--  https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static_interp.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300608 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘finger_far0_non_static_interp.npy’\n",
            "\n",
            "finger_far0_non_sta 100%[===================>]   2.19M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-09-29 10:03:06 (26.0 MB/s) - ‘finger_far0_non_static_interp.npy’ saved [2300608/2300608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K77KboXc7QkC",
        "outputId": "99bc15d5-659a-48e9-8306-815d507fe4b6"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finger_far0_non_static_interp.npy  finger_far0_non_static.npy  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Tensorflow implementation"
      ],
      "metadata": {
        "id": "2cj2oAJR7XvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Implementation based on define-by-run (eager execution)"
      ],
      "metadata": {
        "id": "sQAF02d-7asq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_interp_tf_eager(track):\n",
        "    orig_shape = tf.shape(track)\n",
        "    tlength = orig_shape[0]\n",
        "    mask = track[:, 0, -1] != 0\n",
        "    valid = tf.reduce_sum(tf.cast(mask, dtype=tf.int32))\n",
        "    if valid == tlength:\n",
        "        y = track\n",
        "    else:\n",
        "        xs = tf.where(mask)\n",
        "        xs = tf.reshape(xs, [valid])\n",
        "        # determine the output data type\n",
        "        ys = tf.reshape(track, [tlength, -1])\n",
        "        ys = tf.gather(ys, xs, axis=0)\n",
        "        x = tf.range(tlength)\n",
        "        dtype_ys = ys.dtype\n",
        "\n",
        "        # normalize data types\n",
        "        xs = tf.cast(xs, dtype_ys)\n",
        "        x = tf.cast(x, dtype_ys)\n",
        "\n",
        "        # pad control points for extrapolation\n",
        "        xs = tf.concat([[xs.dtype.min], xs, [xs.dtype.max]], axis=0)\n",
        "        ys = tf.concat([ys[:1], ys, ys[-1:]], axis=0)\n",
        "\n",
        "        # compute slopes, pad at the edges to flatten\n",
        "        ms = (ys[1:] - ys[:-1]) / tf.expand_dims((xs[1:] - xs[:-1]), axis=-1)\n",
        "        ms = tf.pad(ms[:-1], [(1, 1), (0, 0)])\n",
        "\n",
        "        # solve for intercepts\n",
        "        bs = ys - ms * tf.expand_dims(xs, axis=-1)\n",
        "\n",
        "        # search for the line parameters at each input data point\n",
        "        # create a grid of the inputs and piece breakpoints for thresholding\n",
        "        # rely on argmax stopping on the first true when there are duplicates,\n",
        "        # which gives us an index into the parameter vectors\n",
        "        i = tf.math.argmax(tf.expand_dims(xs, axis=-2) > tf.expand_dims(x, axis=-1), axis=-1)\n",
        "        m = tf.gather(ms, i, axis=0)\n",
        "        b = tf.gather(bs, i, axis=0)\n",
        "\n",
        "        # apply the linear mapping at each input data point\n",
        "        y = m*tf.expand_dims(x, axis=-1) + b\n",
        "        y = tf.cast(y, dtype_ys)\n",
        "        y = tf.reshape(y, orig_shape)\n",
        "    return y\n",
        "\n",
        "\n",
        "def partsbased_interp_tf_eager(trackdata):\n",
        "    num_joints = trackdata.shape[1]\n",
        "    trackdata = tf.convert_to_tensor(trackdata)\n",
        "    pose = tf.gather(trackdata, tf.range(0, 33), axis=1)\n",
        "    lhand = tf.gather(trackdata, tf.range(33, 33+21), axis=1)\n",
        "    rhand = tf.gather(trackdata, tf.range(33+21, 33+21+21), axis=1)\n",
        "    face = tf.gather(trackdata, tf.range(33+21+21, num_joints), axis=1)\n",
        "\n",
        "    pose = matrix_interp_tf_eager(pose)\n",
        "    lhand = matrix_interp_tf_eager(lhand)\n",
        "    rhand = matrix_interp_tf_eager(rhand)\n",
        "    face = matrix_interp_tf_eager(face)\n",
        "    return tf.concat([pose, lhand, rhand, face], axis=1)"
      ],
      "metadata": {
        "id": "c2qyp0Zp7hC6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trackdata = np.load(\"finger_far0_non_static.npy\")\n",
        "reftrack = np.load(\"finger_far0_non_static_interp.npy\")\n",
        "# Remove person axis.\n",
        "trackdata = trackdata[0]\n",
        "reftrack = reftrack[0]"
      ],
      "metadata": {
        "id": "rUR_6HgQJbU2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf_eager(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf_eager(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdouNLEF7nXR",
        "outputId": "cd9ff601-7d17-4c90-b906-ea9d43f7442e"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.24913760500000137\n",
            "Average time after second call:0.013600808399999664\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf_eager(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf_eager(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack[:-1] - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiP8savd7ora",
        "outputId": "ca52add6-6075-4434-bf8a-6c5375eae6ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.017207738999999833\n",
            "Average time after second call:0.014746782699999983\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Implementation based on define-and-run (tf.function)"
      ],
      "metadata": {
        "id": "jiXZc_Oo7sTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If input_signature is omitted, the re-tracing is performed when a tensor's shape is changed.\n",
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None, None, 4], dtype=tf.float64),))\n",
        "def matrix_interp_tf(track):\n",
        "    orig_shape = tf.shape(track)\n",
        "    tlength = orig_shape[0]\n",
        "    mask = track[:, 0, -1] != 0\n",
        "    valid = tf.reduce_sum(tf.cast(mask, dtype=tf.int32))\n",
        "    if valid == tlength:\n",
        "        y = track\n",
        "    else:\n",
        "        xs = tf.where(mask)\n",
        "        xs = tf.reshape(xs, [valid])\n",
        "        # determine the output data type\n",
        "        ys = tf.reshape(track, [tlength, -1])\n",
        "        ys = tf.gather(ys, xs, axis=0)\n",
        "        x = tf.range(tlength)\n",
        "        dtype_ys = ys.dtype\n",
        "\n",
        "        # normalize data types\n",
        "        xs = tf.cast(xs, dtype_ys)\n",
        "        x = tf.cast(x, dtype_ys)\n",
        "\n",
        "        # pad control points for extrapolation\n",
        "        xs = tf.concat([[xs.dtype.min], xs, [xs.dtype.max]], axis=0)\n",
        "        ys = tf.concat([ys[:1], ys, ys[-1:]], axis=0)\n",
        "\n",
        "        # compute slopes, pad at the edges to flatten\n",
        "        ms = (ys[1:] - ys[:-1]) / tf.expand_dims((xs[1:] - xs[:-1]), axis=-1)\n",
        "        ms = tf.pad(ms[:-1], [(1, 1), (0, 0)])\n",
        "\n",
        "        # solve for intercepts\n",
        "        bs = ys - ms * tf.expand_dims(xs, axis=-1)\n",
        "\n",
        "        # search for the line parameters at each input data point\n",
        "        # create a grid of the inputs and piece breakpoints for thresholding\n",
        "        # rely on argmax stopping on the first true when there are duplicates,\n",
        "        # which gives us an index into the parameter vectors\n",
        "        i = tf.math.argmax(tf.expand_dims(xs, axis=-2) > tf.expand_dims(x, axis=-1), axis=-1)\n",
        "        m = tf.gather(ms, i, axis=0)\n",
        "        b = tf.gather(bs, i, axis=0)\n",
        "\n",
        "        # apply the linear mapping at each input data point\n",
        "        y = m*tf.expand_dims(x, axis=-1) + b\n",
        "        y = tf.cast(y, dtype_ys)\n",
        "        y = tf.reshape(y, orig_shape)\n",
        "    return y\n",
        "\n",
        "\n",
        "def partsbased_interp_tf(trackdata):\n",
        "    num_joints = trackdata.shape[1]\n",
        "    trackdata = tf.convert_to_tensor(trackdata)\n",
        "    pose = tf.gather(trackdata, tf.range(0, 33), axis=1)\n",
        "    lhand = tf.gather(trackdata, tf.range(33, 33+21), axis=1)\n",
        "    rhand = tf.gather(trackdata, tf.range(33+21, 33+21+21), axis=1)\n",
        "    face = tf.gather(trackdata, tf.range(33+21+21, num_joints), axis=1)\n",
        "\n",
        "    pose = matrix_interp_tf(pose)\n",
        "    lhand = matrix_interp_tf(lhand)\n",
        "    rhand = matrix_interp_tf(rhand)\n",
        "    face = matrix_interp_tf(face)\n",
        "    return tf.concat([pose, lhand, rhand, face], axis=1)"
      ],
      "metadata": {
        "id": "4rTmEJoX7w6K"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2XLppGLJUqU",
        "outputId": "ee262c19-f319-478d-cf51-b068d67ea689"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.3889126279999999\n",
            "Average time after second call:0.006037442600000986\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack[:-1] - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT4RbjQiJ2It",
        "outputId": "4c7e265b-c8dd-4e8a-bbcf-561a15aeb543"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.012303197999997906\n",
            "Average time after second call:0.006144258700000194\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    }
  ]
}