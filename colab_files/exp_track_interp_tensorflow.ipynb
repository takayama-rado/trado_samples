{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOeZK0+pGGt3fPoDsl/sU9V",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takayama-rado/trado_samples/blob/main/colab_files/exp_track_interp_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load library"
      ],
      "metadata": {
        "id": "1a3HS9LJ69qT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wnoKLBpt60HT"
      },
      "outputs": [],
      "source": [
        "# Standard modules.\n",
        "import time\n",
        "\n",
        "# CV/ML.\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load data"
      ],
      "metadata": {
        "id": "DE9T4_xs7KtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6seTTj27MQy",
        "outputId": "4a8a3f86-70c3-45de-ba2a-0766693be372"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-04 02:52:38--  https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static.npy\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static.npy [following]\n",
            "--2023-10-04 02:52:39--  https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300608 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘finger_far0_non_static.npy’\n",
            "\n",
            "finger_far0_non_sta 100%[===================>]   2.19M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-04 02:52:39 (43.4 MB/s) - ‘finger_far0_non_static.npy’ saved [2300608/2300608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static_interp.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8y0T9ST7OQU",
        "outputId": "a4dbfc3c-0114-4f42-984f-984c80e5d931"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-04 02:52:39--  https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static_interp.npy\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static_interp.npy [following]\n",
            "--2023-10-04 02:52:39--  https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static_interp.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300608 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘finger_far0_non_static_interp.npy’\n",
            "\n",
            "finger_far0_non_sta 100%[===================>]   2.19M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2023-10-04 02:52:40 (44.1 MB/s) - ‘finger_far0_non_static_interp.npy’ saved [2300608/2300608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K77KboXc7QkC",
        "outputId": "346f5378-168e-479b-c8b2-bf4e78c04ca1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finger_far0_non_static_interp.npy  finger_far0_non_static.npy  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Tensorflow implementation"
      ],
      "metadata": {
        "id": "2cj2oAJR7XvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Implementation based on define-by-run (eager execution)"
      ],
      "metadata": {
        "id": "sQAF02d-7asq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_interp_tf_eager(track):\n",
        "    orig_shape = tf.shape(track)\n",
        "    tlength = orig_shape[0]\n",
        "    mask = track[:, 0, -1] != 0\n",
        "    valid = tf.reduce_sum(tf.cast(mask, dtype=tf.int32))\n",
        "    if valid == tlength:\n",
        "        y = track\n",
        "    else:\n",
        "        xs = tf.where(mask)\n",
        "        xs = tf.reshape(xs, [valid])\n",
        "        # determine the output data type\n",
        "        ys = tf.reshape(track, [tlength, -1])\n",
        "        ys = tf.gather(ys, xs, axis=0)\n",
        "        x = tf.range(tlength)\n",
        "        dtype_ys = ys.dtype\n",
        "\n",
        "        # normalize data types\n",
        "        xs = tf.cast(xs, dtype_ys)\n",
        "        x = tf.cast(x, dtype_ys)\n",
        "\n",
        "        # pad control points for extrapolation\n",
        "        xs = tf.concat([[xs.dtype.min], xs, [xs.dtype.max]], axis=0)\n",
        "        ys = tf.concat([ys[:1], ys, ys[-1:]], axis=0)\n",
        "\n",
        "        # compute slopes, pad at the edges to flatten\n",
        "        sloops = (ys[1:] - ys[:-1]) / tf.expand_dims((xs[1:] - xs[:-1]), axis=-1)\n",
        "        sloops = tf.pad(sloops[:-1], [(1, 1), (0, 0)])\n",
        "\n",
        "        # solve for intercepts\n",
        "        intercepts = ys - sloops * tf.expand_dims(xs, axis=-1)\n",
        "\n",
        "        # search for the line parameters at each input data point\n",
        "        # create a grid of the inputs and piece breakpoints for thresholding\n",
        "        # rely on argmax stopping on the first true when there are duplicates,\n",
        "        # which gives us an index into the parameter vectors\n",
        "        idx = tf.math.argmax(tf.expand_dims(xs, axis=-2) > tf.expand_dims(x, axis=-1), axis=-1)\n",
        "        sloop = tf.gather(sloops, idx, axis=0)\n",
        "        intercept = tf.gather(intercepts, idx, axis=0)\n",
        "\n",
        "        # apply the linear mapping at each input data point\n",
        "        y = sloop * tf.expand_dims(x, axis=-1) + intercept\n",
        "        y = tf.cast(y, dtype_ys)\n",
        "        y = tf.reshape(y, orig_shape)\n",
        "    return y\n",
        "\n",
        "\n",
        "def partsbased_interp_tf_eager(trackdata):\n",
        "    num_joints = trackdata.shape[1]\n",
        "    trackdata = tf.convert_to_tensor(trackdata)\n",
        "    pose = tf.gather(trackdata, tf.range(0, 33), axis=1)\n",
        "    lhand = tf.gather(trackdata, tf.range(33, 33+21), axis=1)\n",
        "    rhand = tf.gather(trackdata, tf.range(33+21, 33+21+21), axis=1)\n",
        "    face = tf.gather(trackdata, tf.range(33+21+21, num_joints), axis=1)\n",
        "\n",
        "    pose = matrix_interp_tf_eager(pose)\n",
        "    lhand = matrix_interp_tf_eager(lhand)\n",
        "    rhand = matrix_interp_tf_eager(rhand)\n",
        "    face = matrix_interp_tf_eager(face)\n",
        "    return tf.concat([pose, lhand, rhand, face], axis=1)"
      ],
      "metadata": {
        "id": "c2qyp0Zp7hC6"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trackdata = np.load(\"finger_far0_non_static.npy\")\n",
        "reftrack = np.load(\"finger_far0_non_static_interp.npy\")\n",
        "# Remove person axis.\n",
        "trackdata = trackdata[0]\n",
        "reftrack = reftrack[0]"
      ],
      "metadata": {
        "id": "rUR_6HgQJbU2"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf_eager(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf_eager(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZdouNLEF7nXR",
        "outputId": "32990f2d-907e-4bdd-aba1-6d28c6e840b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.27973685999999987\n",
            "Average time after second call:0.01483815559999968\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf_eager(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf_eager(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack[:-1] - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiP8savd7ora",
        "outputId": "a913c059-4078-4bac-e644-38c1c07b56eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.01794102200000225\n",
            "Average time after second call:0.017898202199999956\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.2 Implementation based on define-and-run (tf.function without input_signature)"
      ],
      "metadata": {
        "id": "2DrZxL72mHLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If input_signature is omitted, the re-tracing is performed when a tensor's shape is changed.\n",
        "@tf.function\n",
        "def matrix_interp_tf(track):\n",
        "    orig_shape = tf.shape(track)\n",
        "    tlength = orig_shape[0]\n",
        "    mask = track[:, 0, -1] != 0\n",
        "    valid = tf.reduce_sum(tf.cast(mask, dtype=tf.int32))\n",
        "    if valid == tlength:\n",
        "        y = track\n",
        "    else:\n",
        "        xs = tf.where(mask)\n",
        "        xs = tf.reshape(xs, [valid])\n",
        "        # determine the output data type\n",
        "        ys = tf.reshape(track, [tlength, -1])\n",
        "        ys = tf.gather(ys, xs, axis=0)\n",
        "        x = tf.range(tlength)\n",
        "        dtype_ys = ys.dtype\n",
        "\n",
        "        # normalize data types\n",
        "        xs = tf.cast(xs, dtype_ys)\n",
        "        x = tf.cast(x, dtype_ys)\n",
        "\n",
        "        # pad control points for extrapolation\n",
        "        xs = tf.concat([[xs.dtype.min], xs, [xs.dtype.max]], axis=0)\n",
        "        ys = tf.concat([ys[:1], ys, ys[-1:]], axis=0)\n",
        "\n",
        "        # compute slopes, pad at the edges to flatten\n",
        "        sloops = (ys[1:] - ys[:-1]) / tf.expand_dims((xs[1:] - xs[:-1]), axis=-1)\n",
        "        sloops = tf.pad(sloops[:-1], [(1, 1), (0, 0)])\n",
        "\n",
        "        # solve for intercepts\n",
        "        intercepts = ys - sloops * tf.expand_dims(xs, axis=-1)\n",
        "\n",
        "        # search for the line parameters at each input data point\n",
        "        # create a grid of the inputs and piece breakpoints for thresholding\n",
        "        # rely on argmax stopping on the first true when there are duplicates,\n",
        "        # which gives us an index into the parameter vectors\n",
        "        idx = tf.math.argmax(tf.expand_dims(xs, axis=-2) > tf.expand_dims(x, axis=-1), axis=-1)\n",
        "        sloop = tf.gather(sloops, idx, axis=0)\n",
        "        intercept = tf.gather(intercepts, idx, axis=0)\n",
        "\n",
        "        # apply the linear mapping at each input data point\n",
        "        y = sloop * tf.expand_dims(x, axis=-1) + intercept\n",
        "        y = tf.cast(y, dtype_ys)\n",
        "        y = tf.reshape(y, orig_shape)\n",
        "    return y\n",
        "\n",
        "\n",
        "def partsbased_interp_tf(trackdata):\n",
        "    num_joints = trackdata.shape[1]\n",
        "    trackdata = tf.convert_to_tensor(trackdata)\n",
        "    pose = tf.gather(trackdata, tf.range(0, 33), axis=1)\n",
        "    lhand = tf.gather(trackdata, tf.range(33, 33+21), axis=1)\n",
        "    rhand = tf.gather(trackdata, tf.range(33+21, 33+21+21), axis=1)\n",
        "    face = tf.gather(trackdata, tf.range(33+21+21, num_joints), axis=1)\n",
        "\n",
        "    pose = matrix_interp_tf(pose)\n",
        "    lhand = matrix_interp_tf(lhand)\n",
        "    rhand = matrix_interp_tf(rhand)\n",
        "    face = matrix_interp_tf(face)\n",
        "    return tf.concat([pose, lhand, rhand, face], axis=1)"
      ],
      "metadata": {
        "id": "BF94CrARmRd6"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_xZsFGWmWyx",
        "outputId": "d30ef580-f48b-474c-a007-e1bd1ae36e68"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:1.1181952810000055\n",
            "Average time after second call:0.0143577999999998\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack[:-1] - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_LCbr41mZOZ",
        "outputId": "0efb4a0f-81f1-4d29-a9d5-6ce857f54f19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.5909534030000003\n",
            "Average time after second call:0.007588145999999796\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.3 Implementation based on define-and-run (tf.function with input_signature)"
      ],
      "metadata": {
        "id": "jiXZc_Oo7sTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If input_signature is omitted, the re-tracing is performed when a tensor's shape is changed.\n",
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None, None, 4], dtype=tf.float64),))\n",
        "def matrix_interp_tf(track):\n",
        "    orig_shape = tf.shape(track)\n",
        "    tlength = orig_shape[0]\n",
        "    mask = track[:, 0, -1] != 0\n",
        "    valid = tf.reduce_sum(tf.cast(mask, dtype=tf.int32))\n",
        "    if valid == tlength:\n",
        "        y = track\n",
        "    else:\n",
        "        xs = tf.where(mask)\n",
        "        xs = tf.reshape(xs, [valid])\n",
        "        # determine the output data type\n",
        "        ys = tf.reshape(track, [tlength, -1])\n",
        "        ys = tf.gather(ys, xs, axis=0)\n",
        "        x = tf.range(tlength)\n",
        "        dtype_ys = ys.dtype\n",
        "\n",
        "        # normalize data types\n",
        "        xs = tf.cast(xs, dtype_ys)\n",
        "        x = tf.cast(x, dtype_ys)\n",
        "\n",
        "        # pad control points for extrapolation\n",
        "        xs = tf.concat([[xs.dtype.min], xs, [xs.dtype.max]], axis=0)\n",
        "        ys = tf.concat([ys[:1], ys, ys[-1:]], axis=0)\n",
        "\n",
        "        # compute slopes, pad at the edges to flatten\n",
        "        sloops = (ys[1:] - ys[:-1]) / tf.expand_dims((xs[1:] - xs[:-1]), axis=-1)\n",
        "        sloops = tf.pad(sloops[:-1], [(1, 1), (0, 0)])\n",
        "\n",
        "        # solve for intercepts\n",
        "        intercepts = ys - sloops * tf.expand_dims(xs, axis=-1)\n",
        "\n",
        "        # search for the line parameters at each input data point\n",
        "        # create a grid of the inputs and piece breakpoints for thresholding\n",
        "        # rely on argmax stopping on the first true when there are duplicates,\n",
        "        # which gives us an index into the parameter vectors\n",
        "        idx = tf.math.argmax(tf.expand_dims(xs, axis=-2) > tf.expand_dims(x, axis=-1), axis=-1)\n",
        "        sloop = tf.gather(sloops, idx, axis=0)\n",
        "        intercept = tf.gather(intercepts, idx, axis=0)\n",
        "\n",
        "        # apply the linear mapping at each input data point\n",
        "        y = sloop * tf.expand_dims(x, axis=-1) + intercept\n",
        "        y = tf.cast(y, dtype_ys)\n",
        "        y = tf.reshape(y, orig_shape)\n",
        "    return y\n",
        "\n",
        "\n",
        "def partsbased_interp_tf(trackdata):\n",
        "    num_joints = trackdata.shape[1]\n",
        "    trackdata = tf.convert_to_tensor(trackdata)\n",
        "    pose = tf.gather(trackdata, tf.range(0, 33), axis=1)\n",
        "    lhand = tf.gather(trackdata, tf.range(33, 33+21), axis=1)\n",
        "    rhand = tf.gather(trackdata, tf.range(33+21, 33+21+21), axis=1)\n",
        "    face = tf.gather(trackdata, tf.range(33+21+21, num_joints), axis=1)\n",
        "\n",
        "    pose = matrix_interp_tf(pose)\n",
        "    lhand = matrix_interp_tf(lhand)\n",
        "    rhand = matrix_interp_tf(rhand)\n",
        "    face = matrix_interp_tf(face)\n",
        "    return tf.concat([pose, lhand, rhand, face], axis=1)"
      ],
      "metadata": {
        "id": "4rTmEJoX7w6K"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k2XLppGLJUqU",
        "outputId": "b42ce058-db76-4548-8013-b4642da56cc7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.15119064399999615\n",
            "Average time after second call:0.005672991600000188\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Time of first call:{interval}\")\n",
        "\n",
        "start = time.perf_counter()\n",
        "for _ in range(10):\n",
        "  newtrack = partsbased_interp_tf(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print(f\"Average time after second call:{interval / 10}\")\n",
        "\n",
        "diff = (reftrack[:-1] - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT4RbjQiJ2It",
        "outputId": "2ac69e4d-d88b-4c6a-8df9-ba9eda6d1d81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call:0.009458130999995262\n",
            "Average time after second call:0.006645912900000184\n",
            "Sum of error:-6.935119145623503e-12\n"
          ]
        }
      ]
    }
  ]
}