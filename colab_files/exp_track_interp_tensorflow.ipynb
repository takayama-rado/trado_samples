{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPhawAjRne8pfe9ji2Ldkad",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/takayama-rado/trado_samples/blob/main/colab_files/exp_track_interp_tensorflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load library"
      ],
      "metadata": {
        "id": "1a3HS9LJ69qT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wnoKLBpt60HT"
      },
      "outputs": [],
      "source": [
        "# Standard modules.\n",
        "import gc\n",
        "import sys\n",
        "import time\n",
        "from functools import partial\n",
        "\n",
        "# CV/ML.\n",
        "import numpy as np\n",
        "\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Python:{sys.version}\")\n",
        "print(f\"Numpy:{np.__version__}\")\n",
        "print(f\"Tensorflow:{tf.__version__}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGkiyKmrjXb_",
        "outputId": "04b2eb57-653c-456d-b0d8-b2c215ccf35a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python:3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n",
            "Numpy:1.23.5\n",
            "Tensorflow:2.14.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Load data"
      ],
      "metadata": {
        "id": "DE9T4_xs7KtL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6seTTj27MQy",
        "outputId": "e648f811-db65-454e-816f-fe457e567bc3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-30 04:05:00--  https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static.npy\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static.npy [following]\n",
            "--2023-10-30 04:05:01--  https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300608 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘finger_far0_non_static.npy’\n",
            "\n",
            "finger_far0_non_sta 100%[===================>]   2.19M  --.-KB/s    in 0.08s   \n",
            "\n",
            "2023-10-30 04:05:01 (26.4 MB/s) - ‘finger_far0_non_static.npy’ saved [2300608/2300608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static_interp.npy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u8y0T9ST7OQU",
        "outputId": "ec163907-e057-4497-b45f-18611b4de169"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-30 04:05:01--  https://github.com/takayama-rado/trado_samples/raw/main/test_data/finger_far0_non_static_interp.npy\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static_interp.npy [following]\n",
            "--2023-10-30 04:05:01--  https://raw.githubusercontent.com/takayama-rado/trado_samples/main/test_data/finger_far0_non_static_interp.npy\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2300608 (2.2M) [application/octet-stream]\n",
            "Saving to: ‘finger_far0_non_static_interp.npy’\n",
            "\n",
            "finger_far0_non_sta 100%[===================>]   2.19M  9.47MB/s    in 0.2s    \n",
            "\n",
            "2023-10-30 04:05:02 (9.47 MB/s) - ‘finger_far0_non_static_interp.npy’ saved [2300608/2300608]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K77KboXc7QkC",
        "outputId": "6f98164f-8306-4a3e-fd07-f5f33510296f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "finger_far0_non_static_interp.npy  finger_far0_non_static.npy  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Evaluation settings"
      ],
      "metadata": {
        "id": "vvNjeHlVjdnQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_perf_str(val):\n",
        "    token_si = [\"\", \"m\", \"µ\", \"n\", \"p\"]\n",
        "    exp_si = [1, 1e3, 1e6, 1e9, 1e12]\n",
        "    perf_str = f\"{val:3g}s\"\n",
        "    si = \"\"\n",
        "    sval = val\n",
        "    for token, exp in zip(token_si, exp_si):\n",
        "        if val * exp > 1.0:\n",
        "            si = token\n",
        "            sval = val * exp\n",
        "            break\n",
        "    perf_str = f\"{sval:3g}{si}s\"\n",
        "    return perf_str"
      ],
      "metadata": {
        "id": "mWoaDITdnMpX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_perf_time(intervals, top_k=None):\n",
        "    if top_k is not None:\n",
        "        intervals = np.sort(intervals)[:top_k]\n",
        "    min = intervals.min()\n",
        "    max = intervals.max()\n",
        "    mean = intervals.mean()\n",
        "    std = intervals.std()\n",
        "\n",
        "    smin = get_perf_str(min)\n",
        "    smax = get_perf_str(max)\n",
        "    mean = get_perf_str(mean)\n",
        "    std = get_perf_str(std)\n",
        "    if top_k:\n",
        "        print(f\"Top {top_k} summary: Max {smax}, Min {smin}, Mean +/- Std {mean} +/- {std}\")\n",
        "    else:\n",
        "        print(f\"Overall summary: Max {smax}, Min {smin}, Mean +/- Std {mean} +/- {std}\")"
      ],
      "metadata": {
        "id": "qt3NY3BUngU5"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class PerfMeasure():\n",
        "    def __init__(self,\n",
        "                 trials=100,\n",
        "                 top_k=10):\n",
        "        self.trials = trials\n",
        "        self.top_k = top_k\n",
        "\n",
        "    def __call__(self, func):\n",
        "        gc.collect()\n",
        "        gc.disable()\n",
        "        intervals = []\n",
        "        for _ in range(self.trials):\n",
        "            start = time.perf_counter()\n",
        "            func()\n",
        "            end = time.perf_counter()\n",
        "            intervals.append(end - start)\n",
        "        intervals = np.array(intervals)\n",
        "        print_perf_time(intervals)\n",
        "        if self.top_k:\n",
        "            print_perf_time(intervals, self.top_k)\n",
        "        gc.enable()\n",
        "        gc.collect()"
      ],
      "metadata": {
        "id": "-ghp1LrJjfz4"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TRIALS = 100\n",
        "TOPK = 10\n",
        "pmeasure = PerfMeasure(TRIALS, TOPK)"
      ],
      "metadata": {
        "id": "EAUHv91_jhn_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Tensorflow implementation"
      ],
      "metadata": {
        "id": "2cj2oAJR7XvC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.1 Implementation based on define-by-run (eager execution)"
      ],
      "metadata": {
        "id": "sQAF02d-7asq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matrix_interp_tf_eager(track):\n",
        "    orig_shape = tf.shape(track)\n",
        "    tlength = orig_shape[0]\n",
        "    mask = track[:, 0, -1] != 0\n",
        "    valid = tf.reduce_sum(tf.cast(mask, dtype=tf.int32))\n",
        "    if valid == tlength:\n",
        "        y = track\n",
        "    else:\n",
        "        xs = tf.where(mask)\n",
        "        xs = tf.reshape(xs, [valid])\n",
        "        # determine the output data type\n",
        "        ys = tf.reshape(track, [tlength, -1])\n",
        "        ys = tf.gather(ys, xs, axis=0)\n",
        "        x = tf.range(tlength)\n",
        "        dtype_ys = ys.dtype\n",
        "\n",
        "        # normalize data types\n",
        "        xs = tf.cast(xs, dtype_ys)\n",
        "        x = tf.cast(x, dtype_ys)\n",
        "\n",
        "        # pad control points for extrapolation\n",
        "        xs = tf.concat([[xs.dtype.min], xs, [xs.dtype.max]], axis=0)\n",
        "        ys = tf.concat([ys[:1], ys, ys[-1:]], axis=0)\n",
        "\n",
        "        # compute slopes, pad at the edges to flatten\n",
        "        sloops = (ys[1:] - ys[:-1]) / tf.expand_dims((xs[1:] - xs[:-1]), axis=-1)\n",
        "        sloops = tf.pad(sloops[:-1], [(1, 1), (0, 0)])\n",
        "\n",
        "        # solve for intercepts\n",
        "        intercepts = ys - sloops * tf.expand_dims(xs, axis=-1)\n",
        "\n",
        "        # search for the line parameters at each input data point\n",
        "        # create a grid of the inputs and piece breakpoints for thresholding\n",
        "        # rely on argmax stopping on the first true when there are duplicates,\n",
        "        # which gives us an index into the parameter vectors\n",
        "        idx = tf.math.argmax(tf.expand_dims(xs, axis=-2) > tf.expand_dims(x, axis=-1), axis=-1)\n",
        "        sloop = tf.gather(sloops, idx, axis=0)\n",
        "        intercept = tf.gather(intercepts, idx, axis=0)\n",
        "\n",
        "        # apply the linear mapping at each input data point\n",
        "        y = sloop * tf.expand_dims(x, axis=-1) + intercept\n",
        "        y = tf.cast(y, dtype_ys)\n",
        "        y = tf.reshape(y, orig_shape)\n",
        "    return y\n",
        "\n",
        "\n",
        "def partsbased_interp_tf_eager(trackdata):\n",
        "    num_joints = trackdata.shape[1]\n",
        "    trackdata = tf.convert_to_tensor(trackdata)\n",
        "    pose = tf.gather(trackdata, tf.range(0, 33), axis=1)\n",
        "    lhand = tf.gather(trackdata, tf.range(33, 33+21), axis=1)\n",
        "    rhand = tf.gather(trackdata, tf.range(33+21, 33+21+21), axis=1)\n",
        "    face = tf.gather(trackdata, tf.range(33+21+21, num_joints), axis=1)\n",
        "\n",
        "    pose = matrix_interp_tf_eager(pose)\n",
        "    lhand = matrix_interp_tf_eager(lhand)\n",
        "    rhand = matrix_interp_tf_eager(rhand)\n",
        "    face = matrix_interp_tf_eager(face)\n",
        "    return tf.concat([pose, lhand, rhand, face], axis=1)"
      ],
      "metadata": {
        "id": "c2qyp0Zp7hC6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trackdata = np.load(\"finger_far0_non_static.npy\")\n",
        "reftrack = np.load(\"finger_far0_non_static_interp.npy\")\n",
        "# Remove person axis.\n",
        "trackdata = trackdata[0]\n",
        "reftrack = reftrack[0]"
      ],
      "metadata": {
        "id": "rUR_6HgQJbU2"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "print(f\"Time of first call.\")\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf_eager(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print_perf_time(np.array([interval]))\n",
        "\n",
        "diff = (reftrack - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")\n",
        "\n",
        "print(\"Time after second call.\")\n",
        "target_fn = partial(partsbased_interp_tf_eager, trackdata=trackdata)\n",
        "pmeasure(target_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "86J9jcTujsa4",
        "outputId": "0b2856cb-da88-4c7e-efb7-60dba0ce8939"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call.\n",
            "Overall summary: Max 120.998ms, Min 120.998ms, Mean +/- Std 120.998ms +/-   0s\n",
            "Sum of error:-6.935119145623503e-12\n",
            "Time after second call.\n",
            "Overall summary: Max 61.8187ms, Min 11.2679ms, Mean +/- Std 20.8628ms +/- 8.64964ms\n",
            "Top 10 summary: Max 12.2807ms, Min 11.2679ms, Mean +/- Std 11.7345ms +/- 329.671µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "print(f\"Time of first call.\")\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf_eager(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print_perf_time(np.array([interval]))\n",
        "\n",
        "diff = (reftrack[:-1] - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")\n",
        "\n",
        "print(\"Time after second call.\")\n",
        "target_fn = partial(partsbased_interp_tf_eager, trackdata=trackdata[:-1])\n",
        "pmeasure(target_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OD_uvbRRkGHA",
        "outputId": "ac7108b1-9596-4ff4-8e74-35677c4f9406"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call.\n",
            "Overall summary: Max 30.9785ms, Min 30.9785ms, Mean +/- Std 30.9785ms +/-   0s\n",
            "Sum of error:-6.935119145623503e-12\n",
            "Time after second call.\n",
            "Overall summary: Max 75.0154ms, Min 15.6051ms, Mean +/- Std 23.0584ms +/- 10.6375ms\n",
            "Top 10 summary: Max 17.3485ms, Min 15.6051ms, Mean +/- Std 16.8033ms +/- 521.555µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.2 Implementation based on define-and-run (tf.function without input_signature)"
      ],
      "metadata": {
        "id": "2DrZxL72mHLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If input_signature is omitted, the re-tracing is performed when a tensor's shape is changed.\n",
        "@tf.function\n",
        "def matrix_interp_tf(track):\n",
        "    orig_shape = tf.shape(track)\n",
        "    tlength = orig_shape[0]\n",
        "    mask = track[:, 0, -1] != 0\n",
        "    valid = tf.reduce_sum(tf.cast(mask, dtype=tf.int32))\n",
        "    if valid == tlength:\n",
        "        y = track\n",
        "    else:\n",
        "        xs = tf.where(mask)\n",
        "        xs = tf.reshape(xs, [valid])\n",
        "        # determine the output data type\n",
        "        ys = tf.reshape(track, [tlength, -1])\n",
        "        ys = tf.gather(ys, xs, axis=0)\n",
        "        x = tf.range(tlength)\n",
        "        dtype_ys = ys.dtype\n",
        "\n",
        "        # normalize data types\n",
        "        xs = tf.cast(xs, dtype_ys)\n",
        "        x = tf.cast(x, dtype_ys)\n",
        "\n",
        "        # pad control points for extrapolation\n",
        "        xs = tf.concat([[xs.dtype.min], xs, [xs.dtype.max]], axis=0)\n",
        "        ys = tf.concat([ys[:1], ys, ys[-1:]], axis=0)\n",
        "\n",
        "        # compute slopes, pad at the edges to flatten\n",
        "        sloops = (ys[1:] - ys[:-1]) / tf.expand_dims((xs[1:] - xs[:-1]), axis=-1)\n",
        "        sloops = tf.pad(sloops[:-1], [(1, 1), (0, 0)])\n",
        "\n",
        "        # solve for intercepts\n",
        "        intercepts = ys - sloops * tf.expand_dims(xs, axis=-1)\n",
        "\n",
        "        # search for the line parameters at each input data point\n",
        "        # create a grid of the inputs and piece breakpoints for thresholding\n",
        "        # rely on argmax stopping on the first true when there are duplicates,\n",
        "        # which gives us an index into the parameter vectors\n",
        "        idx = tf.math.argmax(tf.expand_dims(xs, axis=-2) > tf.expand_dims(x, axis=-1), axis=-1)\n",
        "        sloop = tf.gather(sloops, idx, axis=0)\n",
        "        intercept = tf.gather(intercepts, idx, axis=0)\n",
        "\n",
        "        # apply the linear mapping at each input data point\n",
        "        y = sloop * tf.expand_dims(x, axis=-1) + intercept\n",
        "        y = tf.cast(y, dtype_ys)\n",
        "        y = tf.reshape(y, orig_shape)\n",
        "    return y\n",
        "\n",
        "\n",
        "def partsbased_interp_tf(trackdata):\n",
        "    num_joints = trackdata.shape[1]\n",
        "    trackdata = tf.convert_to_tensor(trackdata)\n",
        "    pose = tf.gather(trackdata, tf.range(0, 33), axis=1)\n",
        "    lhand = tf.gather(trackdata, tf.range(33, 33+21), axis=1)\n",
        "    rhand = tf.gather(trackdata, tf.range(33+21, 33+21+21), axis=1)\n",
        "    face = tf.gather(trackdata, tf.range(33+21+21, num_joints), axis=1)\n",
        "\n",
        "    pose = matrix_interp_tf(pose)\n",
        "    lhand = matrix_interp_tf(lhand)\n",
        "    rhand = matrix_interp_tf(rhand)\n",
        "    face = matrix_interp_tf(face)\n",
        "    return tf.concat([pose, lhand, rhand, face], axis=1)"
      ],
      "metadata": {
        "id": "BF94CrARmRd6"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "print(f\"Time of first call.\")\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print_perf_time(np.array([interval]))\n",
        "\n",
        "diff = (reftrack - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")\n",
        "\n",
        "print(\"Time after second call.\")\n",
        "target_fn = partial(partsbased_interp_tf, trackdata=trackdata)\n",
        "pmeasure(target_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4LFFAWDSkaoG",
        "outputId": "6be3b912-5e84-4135-9494-6a22578d79f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call.\n",
            "Overall summary: Max 1.5834s, Min 1.5834s, Mean +/- Std 1.5834s +/-   0s\n",
            "Sum of error:-6.935119145623503e-12\n",
            "Time after second call.\n",
            "Overall summary: Max 70.1215ms, Min 8.67015ms, Mean +/- Std 21.3508ms +/- 10.4774ms\n",
            "Top 10 summary: Max 9.71076ms, Min 8.67015ms, Mean +/- Std 9.19527ms +/- 332.419µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "print(f\"Time of first call.\")\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print_perf_time(np.array([interval]))\n",
        "\n",
        "diff = (reftrack[:-1] - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")\n",
        "\n",
        "print(\"Time after second call.\")\n",
        "target_fn = partial(partsbased_interp_tf, trackdata=trackdata[:-1])\n",
        "pmeasure(target_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_LCbr41mZOZ",
        "outputId": "536740aa-ea75-45b0-8f8c-d2f37bf818c1"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call.\n",
            "Overall summary: Max 1.73487s, Min 1.73487s, Mean +/- Std 1.73487s +/-   0s\n",
            "Sum of error:-6.935119145623503e-12\n",
            "Time after second call.\n",
            "Overall summary: Max 36.0208ms, Min 7.17009ms, Mean +/- Std 14.598ms +/- 5.84049ms\n",
            "Top 10 summary: Max 8.39623ms, Min 7.17009ms, Mean +/- Std 7.99962ms +/- 385.734µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.3 Implementation based on define-and-run (tf.function with input_signature)"
      ],
      "metadata": {
        "id": "jiXZc_Oo7sTi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# If input_signature is omitted, the re-tracing is performed when a tensor's shape is changed.\n",
        "@tf.function(input_signature=(tf.TensorSpec(shape=[None, None, 4], dtype=tf.float64),))\n",
        "def matrix_interp_tf(track):\n",
        "    orig_shape = tf.shape(track)\n",
        "    tlength = orig_shape[0]\n",
        "    mask = track[:, 0, -1] != 0\n",
        "    valid = tf.reduce_sum(tf.cast(mask, dtype=tf.int32))\n",
        "    if valid == tlength:\n",
        "        y = track\n",
        "    else:\n",
        "        xs = tf.where(mask)\n",
        "        xs = tf.reshape(xs, [valid])\n",
        "        # determine the output data type\n",
        "        ys = tf.reshape(track, [tlength, -1])\n",
        "        ys = tf.gather(ys, xs, axis=0)\n",
        "        x = tf.range(tlength)\n",
        "        dtype_ys = ys.dtype\n",
        "\n",
        "        # normalize data types\n",
        "        xs = tf.cast(xs, dtype_ys)\n",
        "        x = tf.cast(x, dtype_ys)\n",
        "\n",
        "        # pad control points for extrapolation\n",
        "        xs = tf.concat([[xs.dtype.min], xs, [xs.dtype.max]], axis=0)\n",
        "        ys = tf.concat([ys[:1], ys, ys[-1:]], axis=0)\n",
        "\n",
        "        # compute slopes, pad at the edges to flatten\n",
        "        sloops = (ys[1:] - ys[:-1]) / tf.expand_dims((xs[1:] - xs[:-1]), axis=-1)\n",
        "        sloops = tf.pad(sloops[:-1], [(1, 1), (0, 0)])\n",
        "\n",
        "        # solve for intercepts\n",
        "        intercepts = ys - sloops * tf.expand_dims(xs, axis=-1)\n",
        "\n",
        "        # search for the line parameters at each input data point\n",
        "        # create a grid of the inputs and piece breakpoints for thresholding\n",
        "        # rely on argmax stopping on the first true when there are duplicates,\n",
        "        # which gives us an index into the parameter vectors\n",
        "        idx = tf.math.argmax(tf.expand_dims(xs, axis=-2) > tf.expand_dims(x, axis=-1), axis=-1)\n",
        "        sloop = tf.gather(sloops, idx, axis=0)\n",
        "        intercept = tf.gather(intercepts, idx, axis=0)\n",
        "\n",
        "        # apply the linear mapping at each input data point\n",
        "        y = sloop * tf.expand_dims(x, axis=-1) + intercept\n",
        "        y = tf.cast(y, dtype_ys)\n",
        "        y = tf.reshape(y, orig_shape)\n",
        "    return y\n",
        "\n",
        "\n",
        "def partsbased_interp_tf(trackdata):\n",
        "    num_joints = trackdata.shape[1]\n",
        "    trackdata = tf.convert_to_tensor(trackdata)\n",
        "    pose = tf.gather(trackdata, tf.range(0, 33), axis=1)\n",
        "    lhand = tf.gather(trackdata, tf.range(33, 33+21), axis=1)\n",
        "    rhand = tf.gather(trackdata, tf.range(33+21, 33+21+21), axis=1)\n",
        "    face = tf.gather(trackdata, tf.range(33+21+21, num_joints), axis=1)\n",
        "\n",
        "    pose = matrix_interp_tf(pose)\n",
        "    lhand = matrix_interp_tf(lhand)\n",
        "    rhand = matrix_interp_tf(rhand)\n",
        "    face = matrix_interp_tf(face)\n",
        "    return tf.concat([pose, lhand, rhand, face], axis=1)"
      ],
      "metadata": {
        "id": "4rTmEJoX7w6K"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "print(f\"Time of first call.\")\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata)\n",
        "interval = time.perf_counter() - start\n",
        "print_perf_time(np.array([interval]))\n",
        "\n",
        "diff = (reftrack - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")\n",
        "\n",
        "print(\"Time after second call.\")\n",
        "target_fn = partial(partsbased_interp_tf, trackdata=trackdata)\n",
        "pmeasure(target_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O1QO-8YxmJwH",
        "outputId": "8a92bcae-d951-47e9-cd88-6c7b1a4446b5"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call.\n",
            "Overall summary: Max 328.611ms, Min 328.611ms, Mean +/- Std 328.611ms +/-   0s\n",
            "Sum of error:-6.935119145623503e-12\n",
            "Time after second call.\n",
            "Overall summary: Max 33.595ms, Min 8.34474ms, Mean +/- Std 10.9117ms +/- 3.95531ms\n",
            "Top 10 summary: Max 8.8418ms, Min 8.34474ms, Mean +/- Std 8.63372ms +/- 153.86µs\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tensorflow.\n",
        "# The 1st call may be slow because of the computation graph construction.\n",
        "print(f\"Time of first call.\")\n",
        "start = time.perf_counter()\n",
        "newtrack = partsbased_interp_tf(trackdata[:-1])\n",
        "interval = time.perf_counter() - start\n",
        "print_perf_time(np.array([interval]))\n",
        "\n",
        "diff = (reftrack[:-1] - newtrack.numpy()).sum()\n",
        "print(f\"Sum of error:{diff}\")\n",
        "\n",
        "print(\"Time after second call.\")\n",
        "target_fn = partial(partsbased_interp_tf, trackdata=trackdata[:-1])\n",
        "pmeasure(target_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-jzWfawmWlH",
        "outputId": "1f4eaf16-aedc-49a9-8c88-3dba2c6631b6"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time of first call.\n",
            "Overall summary: Max 19.1748ms, Min 19.1748ms, Mean +/- Std 19.1748ms +/-   0s\n",
            "Sum of error:-6.935119145623503e-12\n",
            "Time after second call.\n",
            "Overall summary: Max 29.0962ms, Min 5.7848ms, Mean +/- Std 7.69065ms +/- 4.21244ms\n",
            "Top 10 summary: Max 5.92441ms, Min 5.7848ms, Mean +/- Std 5.87683ms +/- 44.1624µs\n"
          ]
        }
      ]
    }
  ]
}